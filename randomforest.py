# randomforest.py

# ê·¸ë˜í”„ ì•ˆ ëœ¨ëŠ” ë¬¸ì œ ë°©ì§€ìš© ë°±ì—”ë“œ ì„¤ì • (í•„ìš”í•œ ê²½ìš°ë§Œ)
import matplotlib
matplotlib.use('TkAgg')  # ì•ˆ ëœ¨ëŠ” ê²½ìš°ë§Œ í™œì„±í™”
import matplotlib.pyplot as plt

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
print("ğŸ“¥ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
X_train = pd.read_csv('X_train.csv')
X_test = pd.read_csv('X_test.csv')
y_train = pd.read_csv('y_train.csv').values.ravel()
y_test = pd.read_csv('y_test.csv').values.ravel()

# âœ… ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
print("ğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ ì¤‘...")
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# âœ… ì˜ˆì¸¡
print("ğŸ” ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
y_pred = model.predict(X_test)

# âœ… ì„±ëŠ¥ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\n[âœ”] MSE: {mse:.4f}")
print(f"[âœ”] R2 Score: {r2:.4f}")

# âœ… ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”
print("ğŸ“Š ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”...")

importances = model.feature_importances_
feature_names = X_train.columns

# ìƒìœ„ 20ê°œ ë³€ìˆ˜ ì‹œê°í™”
indices = importances.argsort()[::-1][:20]
plt.figure(figsize=(12, 6))
plt.bar(range(len(indices)), importances[indices])
plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=45, ha='right')
plt.title("Feature Importance (Top 20)")
plt.tight_layout()

# ê·¸ë˜í”„ í™”ë©´ì— í‘œì‹œ
plt.show()
