{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "data = pd.read_csv('processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts = data['patient_id'].value_counts()\n",
    "patient_counts_pd = pd.DataFrame(patient_counts)\n",
    "patient_counts_pd = patient_counts_pd.loc[patient_counts_pd['count'] > 29]\n",
    "\n",
    "filtered_data = data[data['patient_id'].isin(patient_counts_pd.index)]  # 해당 ID만 남기기\n",
    "filtered_data.to_csv('filtered_id_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_high = 25.34 \n",
    "\n",
    "threshold_low = -2.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=0] MSE: 504.355, R²: -0.165 x_train_count: 408\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         4          2\n",
      "True_mid         10        43         25\n",
      "True_good         1         9          7\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.15      0.25      0.19         8\n",
      "         mid       0.77      0.55      0.64        78\n",
      "        good       0.21      0.41      0.27        17\n",
      "\n",
      "    accuracy                           0.50       103\n",
      "   macro avg       0.38      0.40      0.37       103\n",
      "weighted avg       0.63      0.50      0.55       103\n",
      "\n",
      "[id=1] MSE: 1839.728, R²: -0.099 x_train_count: 932\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4        17         17\n",
      "True_mid          8        25         73\n",
      "True_good         6        19         64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.22      0.11      0.14        38\n",
      "         mid       0.41      0.24      0.30       106\n",
      "        good       0.42      0.72      0.53        89\n",
      "\n",
      "    accuracy                           0.40       233\n",
      "   macro avg       0.35      0.35      0.32       233\n",
      "weighted avg       0.38      0.40      0.36       233\n",
      "\n",
      "[id=3] MSE: 1016.033, R²: 0.016 x_train_count: 1216\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         20        24          1\n",
      "True_mid         22        57         10\n",
      "True_good        21       127         22\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.32      0.44      0.37        45\n",
      "         mid       0.27      0.64      0.38        89\n",
      "        good       0.67      0.13      0.22       170\n",
      "\n",
      "    accuracy                           0.33       304\n",
      "   macro avg       0.42      0.40      0.32       304\n",
      "weighted avg       0.50      0.33      0.29       304\n",
      "\n",
      "[id=4] MSE: 2204.102, R²: -0.421 x_train_count: 344\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         40         6          3\n",
      "True_mid         21         9          3\n",
      "True_good         3         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.82      0.71        49\n",
      "         mid       0.56      0.27      0.37        33\n",
      "        good       0.14      0.20      0.17         5\n",
      "\n",
      "    accuracy                           0.57        87\n",
      "   macro avg       0.44      0.43      0.41        87\n",
      "weighted avg       0.57      0.57      0.55        87\n",
      "\n",
      "[id=5] MSE: 2260.359, R²: 0.060 x_train_count: 551\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         12        15          6\n",
      "True_mid          4        28         10\n",
      "True_good         2        34         27\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.36      0.47        33\n",
      "         mid       0.36      0.67      0.47        42\n",
      "        good       0.63      0.43      0.51        63\n",
      "\n",
      "    accuracy                           0.49       138\n",
      "   macro avg       0.55      0.49      0.48       138\n",
      "weighted avg       0.56      0.49      0.49       138\n",
      "\n",
      "[id=6] MSE: 1790.400, R²: 0.152 x_train_count: 733\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         8         13\n",
      "True_mid          1        36         32\n",
      "True_good         1        25         67\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.05      0.08        22\n",
      "         mid       0.52      0.52      0.52        69\n",
      "        good       0.60      0.72      0.65        93\n",
      "\n",
      "    accuracy                           0.57       184\n",
      "   macro avg       0.48      0.43      0.42       184\n",
      "weighted avg       0.54      0.57      0.54       184\n",
      "\n",
      "[id=7] MSE: 2708.926, R²: -1.465 x_train_count: 402\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         17         6          4\n",
      "True_mid         22        20         10\n",
      "True_good        16         4          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.31      0.63      0.41        27\n",
      "         mid       0.67      0.38      0.49        52\n",
      "        good       0.12      0.09      0.11        22\n",
      "\n",
      "    accuracy                           0.39       101\n",
      "   macro avg       0.37      0.37      0.34       101\n",
      "weighted avg       0.45      0.39      0.38       101\n",
      "\n",
      "[id=8] MSE: 3348.238, R²: -0.866 x_train_count: 155\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         11         3          8\n",
      "True_mid          5         3          6\n",
      "True_good         0         2          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.69      0.50      0.58        22\n",
      "         mid       0.38      0.21      0.27        14\n",
      "        good       0.07      0.33      0.11         3\n",
      "\n",
      "    accuracy                           0.38        39\n",
      "   macro avg       0.38      0.35      0.32        39\n",
      "weighted avg       0.53      0.38      0.43        39\n",
      "\n",
      "[id=9] MSE: 1407.519, R²: 0.095 x_train_count: 488\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         21        18          6\n",
      "True_mid         17        22          9\n",
      "True_good         9        18          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.45      0.47      0.46        45\n",
      "         mid       0.38      0.46      0.42        48\n",
      "        good       0.12      0.07      0.09        29\n",
      "\n",
      "    accuracy                           0.37       122\n",
      "   macro avg       0.31      0.33      0.32       122\n",
      "weighted avg       0.34      0.37      0.35       122\n",
      "\n",
      "[id=10] MSE: 987.050, R²: -0.958 x_train_count: 786\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          5         5          1\n",
      "True_mid         14        53         13\n",
      "True_good        13        71         22\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.16      0.45      0.23        11\n",
      "         mid       0.41      0.66      0.51        80\n",
      "        good       0.61      0.21      0.31       106\n",
      "\n",
      "    accuracy                           0.41       197\n",
      "   macro avg       0.39      0.44      0.35       197\n",
      "weighted avg       0.50      0.41      0.39       197\n",
      "\n",
      "[id=11] MSE: 13558.651, R²: -6.746 x_train_count: 320\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         11         4          7\n",
      "True_mid         21         8         18\n",
      "True_good         4         2          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.31      0.50      0.38        22\n",
      "         mid       0.57      0.17      0.26        47\n",
      "        good       0.17      0.45      0.24        11\n",
      "\n",
      "    accuracy                           0.30        80\n",
      "   macro avg       0.35      0.37      0.30        80\n",
      "weighted avg       0.44      0.30      0.29        80\n",
      "\n",
      "[id=12] MSE: 1001.346, R²: -0.029 x_train_count: 1196\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         76        63          0\n",
      "True_mid         32        80          3\n",
      "True_good         8        34          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.66      0.55      0.60       139\n",
      "         mid       0.45      0.70      0.55       115\n",
      "        good       0.57      0.09      0.15        46\n",
      "\n",
      "    accuracy                           0.53       300\n",
      "   macro avg       0.56      0.44      0.43       300\n",
      "weighted avg       0.56      0.53      0.51       300\n",
      "\n",
      "[id=13] MSE: 2705.426, R²: -0.222 x_train_count: 144\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         1          1\n",
      "True_mid          3         4          7\n",
      "True_good         5         2         10\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.27      0.60      0.38         5\n",
      "         mid       0.57      0.29      0.38        14\n",
      "        good       0.56      0.59      0.57        17\n",
      "\n",
      "    accuracy                           0.47        36\n",
      "   macro avg       0.47      0.49      0.44        36\n",
      "weighted avg       0.52      0.47      0.47        36\n",
      "\n",
      "[id=14] MSE: 785.926, R²: 0.324 x_train_count: 1232\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         87        52          2\n",
      "True_mid         32        75          4\n",
      "True_good         5        47          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.70      0.62      0.66       141\n",
      "         mid       0.43      0.68      0.53       111\n",
      "        good       0.40      0.07      0.12        56\n",
      "\n",
      "    accuracy                           0.54       308\n",
      "   macro avg       0.51      0.45      0.43       308\n",
      "weighted avg       0.55      0.54      0.51       308\n",
      "\n",
      "[id=15] MSE: 519.145, R²: 0.071 x_train_count: 1052\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         4         16\n",
      "True_mid          0        17         24\n",
      "True_good         0        16        186\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        20\n",
      "         mid       0.46      0.41      0.44        41\n",
      "        good       0.82      0.92      0.87       202\n",
      "\n",
      "    accuracy                           0.77       263\n",
      "   macro avg       0.43      0.45      0.44       263\n",
      "weighted avg       0.70      0.77      0.74       263\n",
      "\n",
      "[id=16] MSE: 1691.833, R²: 0.119 x_train_count: 609\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         25        29          6\n",
      "True_mid          9        43         14\n",
      "True_good         8        15          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.42      0.49        60\n",
      "         mid       0.49      0.65      0.56        66\n",
      "        good       0.17      0.15      0.16        27\n",
      "\n",
      "    accuracy                           0.47       153\n",
      "   macro avg       0.42      0.41      0.40       153\n",
      "weighted avg       0.48      0.47      0.46       153\n",
      "\n",
      "[id=17] MSE: 3444.180, R²: -0.469 x_train_count: 483\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         19         4          0\n",
      "True_mid          8        53          9\n",
      "True_good        18         9          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.42      0.83      0.56        23\n",
      "         mid       0.80      0.76      0.78        70\n",
      "        good       0.10      0.04      0.05        28\n",
      "\n",
      "    accuracy                           0.60       121\n",
      "   macro avg       0.44      0.54      0.46       121\n",
      "weighted avg       0.57      0.60      0.57       121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=18] MSE: 4006.266, R²: 0.202 x_train_count: 273\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         50         3          0\n",
      "True_mid          9         0          0\n",
      "True_good         7         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.76      0.94      0.84        53\n",
      "         mid       0.00      0.00      0.00         9\n",
      "        good       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.72        69\n",
      "   macro avg       0.25      0.31      0.28        69\n",
      "weighted avg       0.58      0.72      0.65        69\n",
      "\n",
      "[id=19] MSE: 958.199, R²: 0.427 x_train_count: 873\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         61         9          2\n",
      "True_mid         20       112         14\n",
      "True_good         0         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.75      0.85      0.80        72\n",
      "         mid       0.92      0.77      0.84       146\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.79       219\n",
      "   macro avg       0.56      0.54      0.54       219\n",
      "weighted avg       0.86      0.79      0.82       219\n",
      "\n",
      "[id=20] MSE: 829.449, R²: -0.257 x_train_count: 302\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         17        12          1\n",
      "True_mid         18        20          2\n",
      "True_good         4         2          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.44      0.57      0.49        30\n",
      "         mid       0.59      0.50      0.54        40\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.49        76\n",
      "   macro avg       0.34      0.36      0.34        76\n",
      "weighted avg       0.48      0.49      0.48        76\n",
      "\n",
      "[id=21] MSE: 7608.280, R²: -3.880 x_train_count: 159\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         2          3\n",
      "True_mid          2        11          6\n",
      "True_good         7         1          6\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.18      0.29      0.22         7\n",
      "         mid       0.79      0.58      0.67        19\n",
      "        good       0.40      0.43      0.41        14\n",
      "\n",
      "    accuracy                           0.47        40\n",
      "   macro avg       0.46      0.43      0.43        40\n",
      "weighted avg       0.55      0.47      0.50        40\n",
      "\n",
      "[id=23] MSE: 1277.337, R²: 0.142 x_train_count: 730\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         62        28          3\n",
      "True_mid         18        45          0\n",
      "True_good         9        18          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.70      0.67      0.68        93\n",
      "         mid       0.49      0.71      0.58        63\n",
      "        good       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.58       183\n",
      "   macro avg       0.40      0.46      0.42       183\n",
      "weighted avg       0.52      0.58      0.55       183\n",
      "\n",
      "[id=24] MSE: 1328.257, R²: 0.079 x_train_count: 372\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8         6          2\n",
      "True_mid          4        27         19\n",
      "True_good         9        10          9\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.38      0.50      0.43        16\n",
      "         mid       0.63      0.54      0.58        50\n",
      "        good       0.30      0.32      0.31        28\n",
      "\n",
      "    accuracy                           0.47        94\n",
      "   macro avg       0.44      0.45      0.44        94\n",
      "weighted avg       0.49      0.47      0.47        94\n",
      "\n",
      "[id=25] MSE: 1544.881, R²: -0.160 x_train_count: 545\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         11        15          1\n",
      "True_mid          8        48         19\n",
      "True_good         7        22          6\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.42      0.41      0.42        27\n",
      "         mid       0.56      0.64      0.60        75\n",
      "        good       0.23      0.17      0.20        35\n",
      "\n",
      "    accuracy                           0.47       137\n",
      "   macro avg       0.41      0.41      0.40       137\n",
      "weighted avg       0.45      0.47      0.46       137\n",
      "\n",
      "[id=26] MSE: 12131.012, R²: -4.091 x_train_count: 216\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6         7          8\n",
      "True_mid         11        11          5\n",
      "True_good         1         5          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.29      0.31        21\n",
      "         mid       0.48      0.41      0.44        27\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.31        54\n",
      "   macro avg       0.27      0.23      0.25        54\n",
      "weighted avg       0.37      0.31      0.34        54\n",
      "\n",
      "[id=27] MSE: 3501.865, R²: -1.929 x_train_count: 283\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         1          0\n",
      "True_mid         41        18          3\n",
      "True_good         1         1          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.09      0.80      0.16         5\n",
      "         mid       0.90      0.29      0.44        62\n",
      "        good       0.40      0.50      0.44         4\n",
      "\n",
      "    accuracy                           0.34        71\n",
      "   macro avg       0.46      0.53      0.35        71\n",
      "weighted avg       0.81      0.34      0.42        71\n",
      "\n",
      "[id=28] MSE: 3092.744, R²: -1.022 x_train_count: 149\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         2          2\n",
      "True_mid          7         8          9\n",
      "True_good         3         1          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.17      0.33      0.22         6\n",
      "         mid       0.73      0.33      0.46        24\n",
      "        good       0.27      0.50      0.35         8\n",
      "\n",
      "    accuracy                           0.37        38\n",
      "   macro avg       0.39      0.39      0.34        38\n",
      "weighted avg       0.54      0.37      0.40        38\n",
      "\n",
      "[id=30] MSE: 1055.555, R²: 0.064 x_train_count: 349\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         21         8          4\n",
      "True_mid          6        21          6\n",
      "True_good         6        14          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.64      0.64      0.64        33\n",
      "         mid       0.49      0.64      0.55        33\n",
      "        good       0.17      0.09      0.12        22\n",
      "\n",
      "    accuracy                           0.50        88\n",
      "   macro avg       0.43      0.45      0.44        88\n",
      "weighted avg       0.46      0.50      0.48        88\n",
      "\n",
      "[id=31] MSE: 5787.721, R²: -2.397 x_train_count: 50\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          3\n",
      "True_mid          2         1          4\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.50      0.55         6\n",
      "         mid       1.00      0.14      0.25         7\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.31        13\n",
      "   macro avg       0.53      0.21      0.27        13\n",
      "weighted avg       0.82      0.31      0.39        13\n",
      "\n",
      "[id=32] MSE: 17258.980, R²: -1.714 x_train_count: 63\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         2          1\n",
      "True_mid          3         1          3\n",
      "True_good         1         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.57      0.53         7\n",
      "         mid       0.25      0.14      0.18         7\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.31        16\n",
      "   macro avg       0.25      0.24      0.24        16\n",
      "weighted avg       0.33      0.31      0.31        16\n",
      "\n",
      "[id=33] MSE: 7673.898, R²: 0.356 x_train_count: 703\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad        101         0          1\n",
      "True_mid         30        40          4\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.77      0.99      0.87       102\n",
      "         mid       1.00      0.54      0.70        74\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80       176\n",
      "   macro avg       0.59      0.51      0.52       176\n",
      "weighted avg       0.87      0.80      0.80       176\n",
      "\n",
      "[id=34] MSE: 1243.056, R²: -1.109 x_train_count: 356\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6        19          3\n",
      "True_mid         17        25          5\n",
      "True_good         6         5          3\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.831e+02, tolerance: 1.242e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.21      0.21      0.21        28\n",
      "         mid       0.51      0.53      0.52        47\n",
      "        good       0.27      0.21      0.24        14\n",
      "\n",
      "    accuracy                           0.38        89\n",
      "   macro avg       0.33      0.32      0.32        89\n",
      "weighted avg       0.38      0.38      0.38        89\n",
      "\n",
      "[id=35] MSE: 1934.569, R²: 0.000 x_train_count: 30\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          4         1          3\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.12      0.22         8\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.12         8\n",
      "   macro avg       0.33      0.04      0.07         8\n",
      "weighted avg       1.00      0.12      0.22         8\n",
      "\n",
      "[id=36] MSE: 1084.725, R²: -0.810 x_train_count: 363\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         12        10          5\n",
      "True_mid         13        25          8\n",
      "True_good         8         7          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.36      0.44      0.40        27\n",
      "         mid       0.60      0.54      0.57        46\n",
      "        good       0.19      0.17      0.18        18\n",
      "\n",
      "    accuracy                           0.44        91\n",
      "   macro avg       0.38      0.38      0.38        91\n",
      "weighted avg       0.45      0.44      0.44        91\n",
      "\n",
      "[id=37] MSE: 2005.753, R²: 0.000 x_train_count: 72\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid         10         2          6\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.11      0.20        18\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11        18\n",
      "   macro avg       0.33      0.04      0.07        18\n",
      "weighted avg       1.00      0.11      0.20        18\n",
      "\n",
      "[id=38] MSE: 2694.789, R²: -0.206 x_train_count: 168\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         10         3          0\n",
      "True_mid          5         8          7\n",
      "True_good         5         3          2\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.77      0.61        13\n",
      "         mid       0.57      0.40      0.47        20\n",
      "        good       0.22      0.20      0.21        10\n",
      "\n",
      "    accuracy                           0.47        43\n",
      "   macro avg       0.43      0.46      0.43        43\n",
      "weighted avg       0.47      0.47      0.45        43\n",
      "\n",
      "[id=39] MSE: 1380.882, R²: -0.470 x_train_count: 871\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          7         9          2\n",
      "True_mid         16        42          8\n",
      "True_good        26        66         42\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.39      0.21        18\n",
      "         mid       0.36      0.64      0.46        66\n",
      "        good       0.81      0.31      0.45       134\n",
      "\n",
      "    accuracy                           0.42       218\n",
      "   macro avg       0.44      0.45      0.37       218\n",
      "weighted avg       0.62      0.42      0.43       218\n",
      "\n",
      "[id=40] MSE: 1158.502, R²: 0.045 x_train_count: 607\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         16        19          1\n",
      "True_mid          5        39          4\n",
      "True_good         9        50          9\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.53      0.44      0.48        36\n",
      "         mid       0.36      0.81      0.50        48\n",
      "        good       0.64      0.13      0.22        68\n",
      "\n",
      "    accuracy                           0.42       152\n",
      "   macro avg       0.51      0.46      0.40       152\n",
      "weighted avg       0.53      0.42      0.37       152\n",
      "\n",
      "[id=42] MSE: 9347.427, R²: 0.159 x_train_count: 588\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         89         0          0\n",
      "True_mid         58         1          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.61      1.00      0.75        89\n",
      "         mid       1.00      0.02      0.03        59\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61       148\n",
      "   macro avg       0.54      0.34      0.26       148\n",
      "weighted avg       0.76      0.61      0.47       148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=43] MSE: 824.682, R²: -0.241 x_train_count: 303\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         7          3\n",
      "True_mid          5        23          7\n",
      "True_good         2        22          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.30      0.23      0.26        13\n",
      "         mid       0.44      0.66      0.53        35\n",
      "        good       0.29      0.14      0.19        28\n",
      "\n",
      "    accuracy                           0.39        76\n",
      "   macro avg       0.34      0.34      0.33        76\n",
      "weighted avg       0.36      0.39      0.36        76\n",
      "\n",
      "[id=44] MSE: 1603.150, R²: 0.102 x_train_count: 753\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad        104        14          0\n",
      "True_mid         51        15          0\n",
      "True_good         4         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.65      0.88      0.75       118\n",
      "         mid       0.50      0.23      0.31        66\n",
      "        good       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.63       189\n",
      "   macro avg       0.38      0.37      0.35       189\n",
      "weighted avg       0.58      0.63      0.58       189\n",
      "\n",
      "[id=45] MSE: 26550.933, R²: -7.517 x_train_count: 88\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          9\n",
      "True_mid          3         0          5\n",
      "True_good         1         0          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.18      0.24        11\n",
      "         mid       0.00      0.00      0.00         8\n",
      "        good       0.12      0.67      0.21         3\n",
      "\n",
      "    accuracy                           0.18        22\n",
      "   macro avg       0.15      0.28      0.15        22\n",
      "weighted avg       0.18      0.18      0.15        22\n",
      "\n",
      "[id=47] MSE: 1743.289, R²: -0.155 x_train_count: 106\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         11         2          1\n",
      "True_mid          8         1          2\n",
      "True_good         1         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.55      0.79      0.65        14\n",
      "         mid       0.25      0.09      0.13        11\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.27      0.29      0.26        27\n",
      "weighted avg       0.39      0.44      0.39        27\n",
      "\n",
      "[id=48] MSE: 384.102, R²: -0.342 x_train_count: 47\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          0\n",
      "True_mid          0         5          6\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         1\n",
      "         mid       1.00      0.45      0.62        11\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.67      0.48      0.54        12\n",
      "weighted avg       1.00      0.50      0.66        12\n",
      "\n",
      "[id=49] MSE: 1231.716, R²: -3.994 x_train_count: 62\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          0\n",
      "True_mid          3         8          3\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+04, tolerance: 5.535e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.279e+02, tolerance: 8.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.40      1.00      0.57         2\n",
      "         mid       1.00      0.57      0.73        14\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.47      0.52      0.43        16\n",
      "weighted avg       0.93      0.62      0.71        16\n",
      "\n",
      "[id=50] MSE: 2700.102, R²: -2.015 x_train_count: 220\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         15         2          1\n",
      "True_mid         14         7          5\n",
      "True_good         3         6          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.47      0.83      0.60        18\n",
      "         mid       0.47      0.27      0.34        26\n",
      "        good       0.33      0.25      0.29        12\n",
      "\n",
      "    accuracy                           0.45        56\n",
      "   macro avg       0.42      0.45      0.41        56\n",
      "weighted avg       0.44      0.45      0.41        56\n",
      "\n",
      "[id=52] MSE: 1139.123, R²: 0.454 x_train_count: 551\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         64        15          1\n",
      "True_mid         14        36          4\n",
      "True_good         1         3          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.81      0.80      0.81        80\n",
      "         mid       0.67      0.67      0.67        54\n",
      "        good       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.72       138\n",
      "   macro avg       0.49      0.49      0.49       138\n",
      "weighted avg       0.73      0.72      0.73       138\n",
      "\n",
      "[id=53] MSE: 1327.335, R²: -0.108 x_train_count: 352\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6         8         11\n",
      "True_mid          9        24         27\n",
      "True_good         1         2          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.38      0.24      0.29        25\n",
      "         mid       0.71      0.40      0.51        60\n",
      "        good       0.03      0.25      0.05         4\n",
      "\n",
      "    accuracy                           0.35        89\n",
      "   macro avg       0.37      0.30      0.28        89\n",
      "weighted avg       0.58      0.35      0.43        89\n",
      "\n",
      "[id=54] MSE: 39188.946, R²: -2.266 x_train_count: 50\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         1          2\n",
      "True_mid          4         2          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.57      0.53         7\n",
      "         mid       0.67      0.33      0.44         6\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.39      0.30      0.33        13\n",
      "weighted avg       0.58      0.46      0.49        13\n",
      "\n",
      "[id=56] MSE: 8416.430, R²: -10.839 x_train_count: 24\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          3\n",
      "True_mid          0         0          2\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.00      0.00      0.00         2\n",
      "        good       0.17      1.00      0.29         1\n",
      "\n",
      "    accuracy                           0.17         6\n",
      "   macro avg       0.06      0.33      0.10         6\n",
      "weighted avg       0.03      0.17      0.05         6\n",
      "\n",
      "[id=57] MSE: 966.475, R²: -9.473 x_train_count: 97\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         1          0\n",
      "True_mid          2        10         11\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.50      0.40         2\n",
      "         mid       0.91      0.43      0.59        23\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.41      0.31      0.33        25\n",
      "weighted avg       0.86      0.44      0.57        25\n",
      "\n",
      "[id=58] MSE: 891.766, R²: -2.748 x_train_count: 159\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          3\n",
      "True_mid          1         4         22\n",
      "True_good         1         1          8\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.80      0.15      0.25        27\n",
      "        good       0.24      0.80      0.37        10\n",
      "\n",
      "    accuracy                           0.30        40\n",
      "   macro avg       0.35      0.32      0.21        40\n",
      "weighted avg       0.60      0.30      0.26        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.657e+02, tolerance: 1.536e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+01, tolerance: 9.332e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=59] MSE: 10493.520, R²: -6.005 x_train_count: 79\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          4\n",
      "True_mid          4         4          4\n",
      "True_good         3         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.12      0.20      0.15         5\n",
      "         mid       1.00      0.33      0.50        12\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.38      0.18      0.22        20\n",
      "weighted avg       0.63      0.25      0.34        20\n",
      "\n",
      "[id=60] MSE: 3490.655, R²: -2.754 x_train_count: 68\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          1\n",
      "True_mid          3         2          6\n",
      "True_good         1         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.67      0.44         3\n",
      "         mid       0.67      0.18      0.29        11\n",
      "        good       0.12      0.33      0.18         3\n",
      "\n",
      "    accuracy                           0.29        17\n",
      "   macro avg       0.38      0.39      0.30        17\n",
      "weighted avg       0.51      0.29      0.30        17\n",
      "\n",
      "[id=62] MSE: 1106.987, R²: -0.938 x_train_count: 851\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         28         7          1\n",
      "True_mid         86        62          7\n",
      "True_good         7        10          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.23      0.78      0.36        36\n",
      "         mid       0.78      0.40      0.53       155\n",
      "        good       0.38      0.23      0.29        22\n",
      "\n",
      "    accuracy                           0.45       213\n",
      "   macro avg       0.47      0.47      0.39       213\n",
      "weighted avg       0.65      0.45      0.48       213\n",
      "\n",
      "[id=63] MSE: 10710.381, R²: -5.379 x_train_count: 126\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          9         1          5\n",
      "True_mid          4         1          5\n",
      "True_good         5         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.60      0.55        15\n",
      "         mid       0.33      0.10      0.15        10\n",
      "        good       0.09      0.14      0.11         7\n",
      "\n",
      "    accuracy                           0.34        32\n",
      "   macro avg       0.31      0.28      0.27        32\n",
      "weighted avg       0.36      0.34      0.33        32\n",
      "\n",
      "[id=64] MSE: 1400.013, R²: -4.027 x_train_count: 24\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         1          0\n",
      "True_mid          1         4          0\n",
      "True_good         1         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.80      0.80      0.80         5\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.27      0.27      0.27         7\n",
      "weighted avg       0.57      0.57      0.57         7\n",
      "\n",
      "[id=66] MSE: 515.330, R²: -47.641 x_train_count: 52\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          3         8          3\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.57      0.73        14\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.33      0.19      0.24        14\n",
      "weighted avg       1.00      0.57      0.73        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+01, tolerance: 1.978e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.993e+01, tolerance: 2.349e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=70] MSE: 20626.357, R²: -24.022 x_train_count: 75\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         1          4\n",
      "True_mid          8         2          4\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         5\n",
      "         mid       0.67      0.14      0.24        14\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11        19\n",
      "   macro avg       0.22      0.05      0.08        19\n",
      "weighted avg       0.49      0.11      0.17        19\n",
      "\n",
      "[id=71] MSE: 3009.045, R²: -3.267 x_train_count: 103\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         1          2\n",
      "True_mid          2         3          5\n",
      "True_good         1         3          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.57      0.57      0.57         7\n",
      "         mid       0.43      0.30      0.35        10\n",
      "        good       0.42      0.56      0.48         9\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.47      0.48      0.47        26\n",
      "weighted avg       0.46      0.46      0.45        26\n",
      "\n",
      "[id=72] MSE: 1641.981, R²: 0.104 x_train_count: 390\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         12         9          1\n",
      "True_mid          4        39         15\n",
      "True_good         5         9          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.57      0.55      0.56        22\n",
      "         mid       0.68      0.67      0.68        58\n",
      "        good       0.20      0.22      0.21        18\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.49      0.48      0.48        98\n",
      "weighted avg       0.57      0.56      0.57        98\n",
      "\n",
      "[id=73] MSE: 6990.366, R²: -5.463 x_train_count: 159\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         1          2\n",
      "True_mid          2        12         19\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.57      0.62         7\n",
      "         mid       0.92      0.36      0.52        33\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40        40\n",
      "   macro avg       0.53      0.31      0.38        40\n",
      "weighted avg       0.88      0.40      0.54        40\n",
      "\n",
      "[id=74] MSE: 2338.602, R²: 0.477 x_train_count: 172\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         20         4          2\n",
      "True_mid          5         3          4\n",
      "True_good         0         2          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.80      0.77      0.78        26\n",
      "         mid       0.33      0.25      0.29        12\n",
      "        good       0.33      0.60      0.43         5\n",
      "\n",
      "    accuracy                           0.60        43\n",
      "   macro avg       0.49      0.54      0.50        43\n",
      "weighted avg       0.62      0.60      0.60        43\n",
      "\n",
      "[id=75] MSE: 10236.521, R²: -5.762 x_train_count: 144\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         1          6\n",
      "True_mid          5         2         20\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.29      0.22      0.25         9\n",
      "         mid       0.67      0.07      0.13        27\n",
      "        good       0.04      1.00      0.07         1\n",
      "\n",
      "    accuracy                           0.14        37\n",
      "   macro avg       0.33      0.43      0.15        37\n",
      "weighted avg       0.56      0.14      0.16        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=76] MSE: 917.162, R²: -1.509 x_train_count: 211\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         7          3\n",
      "True_mid         10        19          7\n",
      "True_good         1         5          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        10\n",
      "         mid       0.61      0.53      0.57        36\n",
      "        good       0.09      0.14      0.11         7\n",
      "\n",
      "    accuracy                           0.38        53\n",
      "   macro avg       0.23      0.22      0.23        53\n",
      "weighted avg       0.43      0.38      0.40        53\n",
      "\n",
      "[id=77] MSE: 1213.046, R²: -0.270 x_train_count: 723\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         31        58         15\n",
      "True_mid         11        51          7\n",
      "True_good         2         5          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.70      0.30      0.42       104\n",
      "         mid       0.45      0.74      0.56        69\n",
      "        good       0.04      0.12      0.06         8\n",
      "\n",
      "    accuracy                           0.46       181\n",
      "   macro avg       0.40      0.39      0.35       181\n",
      "weighted avg       0.58      0.46      0.46       181\n",
      "\n",
      "[id=78] MSE: 1935.936, R²: -0.087 x_train_count: 155\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         4          2\n",
      "True_mid          1         5         10\n",
      "True_good         0         6          9\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.25      0.36         8\n",
      "         mid       0.33      0.31      0.32        16\n",
      "        good       0.43      0.60      0.50        15\n",
      "\n",
      "    accuracy                           0.41        39\n",
      "   macro avg       0.48      0.39      0.40        39\n",
      "weighted avg       0.44      0.41      0.40        39\n",
      "\n",
      "[id=79] MSE: 795.477, R²: 0.260 x_train_count: 508\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          5         7          3\n",
      "True_mid          4        25         10\n",
      "True_good         0        37         36\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.56      0.33      0.42        15\n",
      "         mid       0.36      0.64      0.46        39\n",
      "        good       0.73      0.49      0.59        73\n",
      "\n",
      "    accuracy                           0.52       127\n",
      "   macro avg       0.55      0.49      0.49       127\n",
      "weighted avg       0.60      0.52      0.53       127\n",
      "\n",
      "[id=80] MSE: 3242.166, R²: -0.107 x_train_count: 445\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         79         1          0\n",
      "True_mid         20         3          3\n",
      "True_good         5         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.76      0.99      0.86        80\n",
      "         mid       0.60      0.12      0.19        26\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.73       112\n",
      "   macro avg       0.45      0.37      0.35       112\n",
      "weighted avg       0.68      0.73      0.66       112\n",
      "\n",
      "[id=81] MSE: 1359.094, R²: -0.127 x_train_count: 475\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0        16         17\n",
      "True_mid          0        22         21\n",
      "True_good         0        14         29\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        33\n",
      "         mid       0.42      0.51      0.46        43\n",
      "        good       0.43      0.67      0.53        43\n",
      "\n",
      "    accuracy                           0.43       119\n",
      "   macro avg       0.29      0.40      0.33       119\n",
      "weighted avg       0.31      0.43      0.36       119\n",
      "\n",
      "[id=83] MSE: 1321.378, R²: -0.041 x_train_count: 645\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4        16          3\n",
      "True_mid          4        31         22\n",
      "True_good         3        42         37\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e+01, tolerance: 3.113e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.36      0.17      0.24        23\n",
      "         mid       0.35      0.54      0.42        57\n",
      "        good       0.60      0.45      0.51        82\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.44      0.39      0.39       162\n",
      "weighted avg       0.48      0.44      0.44       162\n",
      "\n",
      "[id=84] MSE: 7636.491, R²: -9.052 x_train_count: 43\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          0\n",
      "True_mid          3         2          0\n",
      "True_good         1         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      1.00      0.60         3\n",
      "         mid       0.67      0.40      0.50         5\n",
      "        good       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.70      0.58      0.53        11\n",
      "weighted avg       0.69      0.55      0.53        11\n",
      "\n",
      "[id=87] MSE: 7327.010, R²: -2.064 x_train_count: 80\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         1          5\n",
      "True_mid          0         3          6\n",
      "True_good         0         1          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.14      0.25         7\n",
      "         mid       0.60      0.33      0.43         9\n",
      "        good       0.27      0.80      0.40         5\n",
      "\n",
      "    accuracy                           0.38        21\n",
      "   macro avg       0.62      0.43      0.36        21\n",
      "weighted avg       0.65      0.38      0.36        21\n",
      "\n",
      "[id=88] MSE: 7512.847, R²: -7.761 x_train_count: 77\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         2          0\n",
      "True_mid          8         1          2\n",
      "True_good         3         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.27      0.67      0.38         6\n",
      "         mid       0.33      0.09      0.14        11\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.20      0.25      0.17        20\n",
      "weighted avg       0.26      0.25      0.19        20\n",
      "\n",
      "[id=89] MSE: 2765.989, R²: -0.828 x_train_count: 388\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0        12         23\n",
      "True_mid          0         6         31\n",
      "True_good         0         3         22\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        35\n",
      "         mid       0.29      0.16      0.21        37\n",
      "        good       0.29      0.88      0.44        25\n",
      "\n",
      "    accuracy                           0.29        97\n",
      "   macro avg       0.19      0.35      0.21        97\n",
      "weighted avg       0.18      0.29      0.19        97\n",
      "\n",
      "[id=90] MSE: 1792.879, R²: 0.309 x_train_count: 196\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          9         1          1\n",
      "True_mid          4        24         10\n",
      "True_good         1         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.64      0.82      0.72        11\n",
      "         mid       0.96      0.63      0.76        38\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.53      0.48      0.49        50\n",
      "weighted avg       0.87      0.66      0.74        50\n",
      "\n",
      "[id=91] MSE: 1068.042, R²: -0.781 x_train_count: 30\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          0\n",
      "True_mid          1         2          1\n",
      "True_good         2         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.40      1.00      0.57         2\n",
      "         mid       1.00      0.50      0.67         4\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.47      0.50      0.41         8\n",
      "weighted avg       0.60      0.50      0.48         8\n",
      "\n",
      "[id=92] MSE: 23738.887, R²: -6.658 x_train_count: 62\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         13         0          1\n",
      "True_mid          1         1          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.93      0.93      0.93        14\n",
      "         mid       1.00      0.50      0.67         2\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.64      0.48      0.53        16\n",
      "weighted avg       0.94      0.88      0.90        16\n",
      "\n",
      "[id=93] MSE: 2668.873, R²: -0.513 x_train_count: 201\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          5         4          0\n",
      "True_mid         12        13         15\n",
      "True_good         0         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.29      0.56      0.38         9\n",
      "         mid       0.72      0.33      0.45        40\n",
      "        good       0.06      0.50      0.11         2\n",
      "\n",
      "    accuracy                           0.37        51\n",
      "   macro avg       0.36      0.46      0.31        51\n",
      "weighted avg       0.62      0.37      0.42        51\n",
      "\n",
      "[id=94] MSE: 9025.900, R²: -5.191 x_train_count: 67\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          0\n",
      "True_mid         13         1          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.19      1.00      0.32         3\n",
      "         mid       1.00      0.07      0.13        14\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24        17\n",
      "   macro avg       0.40      0.36      0.15        17\n",
      "weighted avg       0.86      0.24      0.17        17\n",
      "\n",
      "[id=95] MSE: 9632.648, R²: -23.104 x_train_count: 60\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          4         4          4\n",
      "True_good         1         0          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.33      0.50        12\n",
      "        good       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.48      0.36      0.35        16\n",
      "weighted avg       0.86      0.44      0.51        16\n",
      "\n",
      "[id=96] MSE: 14878.204, R²: -3.062 x_train_count: 196\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          7         0          5\n",
      "True_mid         26        10          1\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.21      0.58      0.31        12\n",
      "         mid       1.00      0.27      0.43        37\n",
      "        good       0.14      1.00      0.25         1\n",
      "\n",
      "    accuracy                           0.36        50\n",
      "   macro avg       0.45      0.62      0.33        50\n",
      "weighted avg       0.79      0.36      0.39        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e+01, tolerance: 2.257e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=97] MSE: 1788.303, R²: -0.013 x_train_count: 698\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8        38          5\n",
      "True_mid          4        43          7\n",
      "True_good         4        55         11\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.16      0.24        51\n",
      "         mid       0.32      0.80      0.45        54\n",
      "        good       0.48      0.16      0.24        70\n",
      "\n",
      "    accuracy                           0.35       175\n",
      "   macro avg       0.43      0.37      0.31       175\n",
      "weighted avg       0.43      0.35      0.30       175\n",
      "\n",
      "[id=98] MSE: 1533.995, R²: -0.422 x_train_count: 522\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         12         9          8\n",
      "True_mid          6        18         25\n",
      "True_good         5        26         22\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.52      0.41      0.46        29\n",
      "         mid       0.34      0.37      0.35        49\n",
      "        good       0.40      0.42      0.41        53\n",
      "\n",
      "    accuracy                           0.40       131\n",
      "   macro avg       0.42      0.40      0.41       131\n",
      "weighted avg       0.40      0.40      0.40       131\n",
      "\n",
      "[id=101] MSE: 1735.495, R²: 0.492 x_train_count: 252\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         25         1          1\n",
      "True_mid          7        17         13\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.78      0.93      0.85        27\n",
      "         mid       0.94      0.46      0.62        37\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.58      0.46      0.49        64\n",
      "weighted avg       0.88      0.66      0.71        64\n",
      "\n",
      "[id=102] MSE: 2382.822, R²: -1.304 x_train_count: 445\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         22        32         28\n",
      "True_mid          0        10         11\n",
      "True_good         1         3          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.96      0.27      0.42        82\n",
      "         mid       0.22      0.48      0.30        21\n",
      "        good       0.11      0.56      0.19         9\n",
      "\n",
      "    accuracy                           0.33       112\n",
      "   macro avg       0.43      0.43      0.30       112\n",
      "weighted avg       0.75      0.33      0.38       112\n",
      "\n",
      "[id=103] MSE: 923.953, R²: -2.850 x_train_count: 88\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         2          0\n",
      "True_mid          1         2         10\n",
      "True_good         1         1          5\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.084e+01, tolerance: 7.122e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.40      0.15      0.22        13\n",
      "        good       0.33      0.71      0.45         7\n",
      "\n",
      "    accuracy                           0.32        22\n",
      "   macro avg       0.24      0.29      0.23        22\n",
      "weighted avg       0.34      0.32      0.28        22\n",
      "\n",
      "[id=104] MSE: 2908.546, R²: -0.349 x_train_count: 123\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          7         2          0\n",
      "True_mid          5         3         11\n",
      "True_good         1         2          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.54      0.78      0.64         9\n",
      "         mid       0.43      0.16      0.23        19\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.32        31\n",
      "   macro avg       0.32      0.31      0.29        31\n",
      "weighted avg       0.42      0.32      0.33        31\n",
      "\n",
      "[id=105] MSE: 3625.838, R²: -1.312 x_train_count: 364\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         10         8          4\n",
      "True_mid         18        12         11\n",
      "True_good        14         9          6\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.24      0.45      0.31        22\n",
      "         mid       0.41      0.29      0.34        41\n",
      "        good       0.29      0.21      0.24        29\n",
      "\n",
      "    accuracy                           0.30        92\n",
      "   macro avg       0.31      0.32      0.30        92\n",
      "weighted avg       0.33      0.30      0.30        92\n",
      "\n",
      "[id=106] MSE: 1576.928, R²: -0.756 x_train_count: 146\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         1          3\n",
      "True_mid          2         2          7\n",
      "True_good         3         4         12\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.38      0.43      0.40         7\n",
      "         mid       0.29      0.18      0.22        11\n",
      "        good       0.55      0.63      0.59        19\n",
      "\n",
      "    accuracy                           0.46        37\n",
      "   macro avg       0.40      0.41      0.40        37\n",
      "weighted avg       0.44      0.46      0.44        37\n",
      "\n",
      "[id=109] MSE: 783.274, R²: -2.984 x_train_count: 93\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          0\n",
      "True_mid          3        13          7\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      1.00      0.40         1\n",
      "         mid       1.00      0.57      0.72        23\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.58        24\n",
      "   macro avg       0.42      0.52      0.37        24\n",
      "weighted avg       0.97      0.58      0.71        24\n",
      "\n",
      "[id=110] MSE: 2630.457, R²: -1.100 x_train_count: 114\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6         2          0\n",
      "True_mid         10         4          1\n",
      "True_good         6         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.27      0.75      0.40         8\n",
      "         mid       0.67      0.27      0.38        15\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.34        29\n",
      "   macro avg       0.31      0.34      0.26        29\n",
      "weighted avg       0.42      0.34      0.31        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.265e+01, tolerance: 1.092e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=111] MSE: 991.169, R²: 0.017 x_train_count: 607\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         5         13\n",
      "True_mid          1        11         25\n",
      "True_good         1        17         77\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.10      0.17        20\n",
      "         mid       0.33      0.30      0.31        37\n",
      "        good       0.67      0.81      0.73        95\n",
      "\n",
      "    accuracy                           0.59       152\n",
      "   macro avg       0.50      0.40      0.40       152\n",
      "weighted avg       0.57      0.59      0.56       152\n",
      "\n",
      "[id=113] MSE: 5182.161, R²: -0.601 x_train_count: 84\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          1\n",
      "True_mid          1         3          8\n",
      "True_good         2         1          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.40      0.67      0.50         3\n",
      "         mid       0.75      0.25      0.38        12\n",
      "        good       0.25      0.50      0.33         6\n",
      "\n",
      "    accuracy                           0.38        21\n",
      "   macro avg       0.47      0.47      0.40        21\n",
      "weighted avg       0.56      0.38      0.38        21\n",
      "\n",
      "[id=115] MSE: 6798.653, R²: -4.100 x_train_count: 164\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         2          4\n",
      "True_mid          9         3         18\n",
      "True_good         0         1          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.10      0.14      0.12         7\n",
      "         mid       0.50      0.10      0.17        30\n",
      "        good       0.15      0.80      0.26         5\n",
      "\n",
      "    accuracy                           0.19        42\n",
      "   macro avg       0.25      0.35      0.18        42\n",
      "weighted avg       0.39      0.19      0.17        42\n",
      "\n",
      "[id=116] MSE: 1044.014, R²: 0.090 x_train_count: 382\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         22        16          1\n",
      "True_mid         20        20          1\n",
      "True_good         4        12          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.48      0.56      0.52        39\n",
      "         mid       0.42      0.49      0.45        41\n",
      "        good       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.44        96\n",
      "   macro avg       0.30      0.35      0.32        96\n",
      "weighted avg       0.37      0.44      0.40        96\n",
      "\n",
      "[id=117] MSE: 3031.896, R²: -0.266 x_train_count: 403\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         17        14          7\n",
      "True_mid          9        22         17\n",
      "True_good         4         7          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.57      0.45      0.50        38\n",
      "         mid       0.51      0.46      0.48        48\n",
      "        good       0.14      0.27      0.19        15\n",
      "\n",
      "    accuracy                           0.43       101\n",
      "   macro avg       0.41      0.39      0.39       101\n",
      "weighted avg       0.48      0.43      0.45       101\n",
      "\n",
      "[id=119] MSE: 14288.759, R²: -6.061 x_train_count: 706\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad        173         3          1\n",
      "True_mid          0         0          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.98      0.99       177\n",
      "         mid       0.00      0.00      0.00         0\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98       177\n",
      "   macro avg       0.33      0.33      0.33       177\n",
      "weighted avg       1.00      0.98      0.99       177\n",
      "\n",
      "[id=121] MSE: 1795.868, R²: -1.228 x_train_count: 208\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          9         7          3\n",
      "True_mid          8        12          9\n",
      "True_good         3         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.45      0.47      0.46        19\n",
      "         mid       0.60      0.41      0.49        29\n",
      "        good       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.40        52\n",
      "   macro avg       0.35      0.30      0.32        52\n",
      "weighted avg       0.50      0.40      0.44        52\n",
      "\n",
      "[id=122] MSE: 1794.961, R²: 0.203 x_train_count: 325\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         13        12          3\n",
      "True_mid         10        22         14\n",
      "True_good         3         5          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.46      0.48        28\n",
      "         mid       0.56      0.48      0.52        46\n",
      "        good       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        82\n",
      "   macro avg       0.35      0.31      0.33        82\n",
      "weighted avg       0.49      0.43      0.45        82\n",
      "\n",
      "[id=123] MSE: 4306.409, R²: -1.146 x_train_count: 138\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8         3          1\n",
      "True_mid          1         6         12\n",
      "True_good         2         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.73      0.67      0.70        12\n",
      "         mid       0.60      0.32      0.41        19\n",
      "        good       0.07      0.25      0.11         4\n",
      "\n",
      "    accuracy                           0.43        35\n",
      "   macro avg       0.47      0.41      0.41        35\n",
      "weighted avg       0.58      0.43      0.48        35\n",
      "\n",
      "[id=125] MSE: 6291.262, R²: -3.742 x_train_count: 88\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         1          2\n",
      "True_mid          1         1         11\n",
      "True_good         0         1          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.40      0.50         5\n",
      "         mid       0.33      0.08      0.12        13\n",
      "        good       0.24      0.80      0.36         5\n",
      "\n",
      "    accuracy                           0.30        23\n",
      "   macro avg       0.41      0.43      0.33        23\n",
      "weighted avg       0.38      0.30      0.26        23\n",
      "\n",
      "[id=128] MSE: 1475.808, R²: 0.305 x_train_count: 230\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          9         5          1\n",
      "True_mid          8        18          8\n",
      "True_good         4         2          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      0.60      0.50        15\n",
      "         mid       0.72      0.53      0.61        34\n",
      "        good       0.25      0.33      0.29         9\n",
      "\n",
      "    accuracy                           0.52        58\n",
      "   macro avg       0.47      0.49      0.47        58\n",
      "weighted avg       0.57      0.52      0.53        58\n",
      "\n",
      "[id=129] MSE: 19668.759, R²: -7.602 x_train_count: 121\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          3\n",
      "True_mid          8         2          5\n",
      "True_good         4         0          6\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.20      0.50      0.29         6\n",
      "         mid       1.00      0.13      0.24        15\n",
      "        good       0.43      0.60      0.50        10\n",
      "\n",
      "    accuracy                           0.35        31\n",
      "   macro avg       0.54      0.41      0.34        31\n",
      "weighted avg       0.66      0.35      0.33        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.625e+02, tolerance: 2.163e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.959e+02, tolerance: 9.695e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.720e+02, tolerance: 1.058e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=130] MSE: 90999.675, R²: -151.154 x_train_count: 49\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          4\n",
      "True_mid          1         0          7\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         4\n",
      "         mid       0.00      0.00      0.00         8\n",
      "        good       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.08        13\n",
      "   macro avg       0.03      0.33      0.05        13\n",
      "weighted avg       0.01      0.08      0.01        13\n",
      "\n",
      "[id=131] MSE: 1482.597, R²: 0.295 x_train_count: 541\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         25        18          4\n",
      "True_mid          7        30         23\n",
      "True_good         5        14         10\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.68      0.53      0.60        47\n",
      "         mid       0.48      0.50      0.49        60\n",
      "        good       0.27      0.34      0.30        29\n",
      "\n",
      "    accuracy                           0.48       136\n",
      "   macro avg       0.48      0.46      0.46       136\n",
      "weighted avg       0.50      0.48      0.49       136\n",
      "\n",
      "[id=133] MSE: 2183.504, R²: -0.537 x_train_count: 74\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          1\n",
      "True_mid          5         6          1\n",
      "True_good         1         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.75      0.46         4\n",
      "         mid       0.86      0.50      0.63        12\n",
      "        good       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.51      0.53      0.48        19\n",
      "weighted avg       0.66      0.53      0.55        19\n",
      "\n",
      "[id=134] MSE: 24418.737, R²: -67.514 x_train_count: 53\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          1\n",
      "True_mid          2         2          9\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       1.00      0.15      0.27        13\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.14        14\n",
      "   macro avg       0.33      0.05      0.09        14\n",
      "weighted avg       0.93      0.14      0.25        14\n",
      "\n",
      "[id=135] MSE: 654.867, R²: -0.278 x_train_count: 240\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          1\n",
      "True_mid         11        32         15\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.08      0.50      0.14         2\n",
      "         mid       1.00      0.55      0.71        58\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55        60\n",
      "   macro avg       0.36      0.35      0.28        60\n",
      "weighted avg       0.97      0.55      0.69        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+02, tolerance: 5.661e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=136] MSE: 14997.895, R²: -10.288 x_train_count: 39\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         1          1\n",
      "True_mid          0         0          5\n",
      "True_good         0         0          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.00      0.00      0.00         5\n",
      "        good       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.11      0.33      0.17        10\n",
      "weighted avg       0.10      0.30      0.15        10\n",
      "\n",
      "[id=138] MSE: 865.108, R²: -0.364 x_train_count: 400\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         20        16          5\n",
      "True_mid          8        24         13\n",
      "True_good         6         2          6\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.59      0.49      0.53        41\n",
      "         mid       0.57      0.53      0.55        45\n",
      "        good       0.25      0.43      0.32        14\n",
      "\n",
      "    accuracy                           0.50       100\n",
      "   macro avg       0.47      0.48      0.47       100\n",
      "weighted avg       0.53      0.50      0.51       100\n",
      "\n",
      "[id=139] MSE: 2089.742, R²: -3.246 x_train_count: 182\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          5         5          2\n",
      "True_mid          3         6         17\n",
      "True_good         0         4          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.42      0.50        12\n",
      "         mid       0.40      0.23      0.29        26\n",
      "        good       0.17      0.50      0.26         8\n",
      "\n",
      "    accuracy                           0.33        46\n",
      "   macro avg       0.40      0.38      0.35        46\n",
      "weighted avg       0.42      0.33      0.34        46\n",
      "\n",
      "[id=140] MSE: 3290.482, R²: -2.110 x_train_count: 61\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         2          1\n",
      "True_mid          0         6          2\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.57      0.73         7\n",
      "         mid       0.75      0.75      0.75         8\n",
      "        good       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.67      0.77      0.63        16\n",
      "weighted avg       0.83      0.69      0.72        16\n",
      "\n",
      "[id=141] MSE: 1567.726, R²: 0.171 x_train_count: 253\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         22         8          5\n",
      "True_mid          3         6         13\n",
      "True_good         1         2          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.85      0.63      0.72        35\n",
      "         mid       0.38      0.27      0.32        22\n",
      "        good       0.18      0.57      0.28         7\n",
      "\n",
      "    accuracy                           0.50        64\n",
      "   macro avg       0.47      0.49      0.44        64\n",
      "weighted avg       0.61      0.50      0.53        64\n",
      "\n",
      "[id=142] MSE: 2785.346, R²: -2.012 x_train_count: 86\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         2          0\n",
      "True_mid          1         1          3\n",
      "True_good         7         5          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.12      0.20      0.15         5\n",
      "        good       0.50      0.20      0.29        15\n",
      "\n",
      "    accuracy                           0.18        22\n",
      "   macro avg       0.21      0.13      0.15        22\n",
      "weighted avg       0.37      0.18      0.23        22\n",
      "\n",
      "[id=143] MSE: 5699.904, R²: -3156.724 x_train_count: 84\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          7         6          9\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.27      0.43        22\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.27        22\n",
      "   macro avg       0.33      0.09      0.14        22\n",
      "weighted avg       1.00      0.27      0.43        22\n",
      "\n",
      "[id=144] MSE: 4519.644, R²: -4.240 x_train_count: 72\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          7         1          1\n",
      "True_mid          4         1          2\n",
      "True_good         2         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.54      0.78      0.64         9\n",
      "         mid       0.50      0.14      0.22         7\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.35      0.31      0.29        18\n",
      "weighted avg       0.46      0.44      0.40        18\n",
      "\n",
      "[id=145] MSE: 4585.267, R²: -0.316 x_train_count: 308\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6         3         16\n",
      "True_mid          5        17         13\n",
      "True_good         2         4         12\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.302e+01, tolerance: 1.174e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+01, tolerance: 1.157e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.927e+01, tolerance: 1.256e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.298e+01, tolerance: 7.594e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.46      0.24      0.32        25\n",
      "         mid       0.71      0.49      0.58        35\n",
      "        good       0.29      0.67      0.41        18\n",
      "\n",
      "    accuracy                           0.45        78\n",
      "   macro avg       0.49      0.46      0.43        78\n",
      "weighted avg       0.53      0.45      0.45        78\n",
      "\n",
      "[id=146] MSE: 8603.031, R²: -3.044 x_train_count: 52\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          2\n",
      "True_mid          5         2          3\n",
      "True_good         1         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.33      0.20         3\n",
      "         mid       1.00      0.20      0.33        10\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.38      0.18      0.18        14\n",
      "weighted avg       0.74      0.21      0.28        14\n",
      "\n",
      "[id=147] MSE: 4812.762, R²: 0.401 x_train_count: 24\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          0\n",
      "True_mid          2         0          1\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      1.00      0.75         3\n",
      "         mid       0.00      0.00      0.00         3\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.20      0.33      0.25         6\n",
      "weighted avg       0.30      0.50      0.38         6\n",
      "\n",
      "[id=149] MSE: 972.030, R²: -4.557 x_train_count: 92\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          2\n",
      "True_mid          5        12          4\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       1.00      0.57      0.73        21\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52        23\n",
      "   macro avg       0.33      0.19      0.24        23\n",
      "weighted avg       0.91      0.52      0.66        23\n",
      "\n",
      "[id=150] MSE: 344.438, R²: 0.325 x_train_count: 277\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          0\n",
      "True_mid          0        29         25\n",
      "True_good         2         9          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      1.00      0.50         1\n",
      "         mid       0.76      0.54      0.63        54\n",
      "        good       0.14      0.27      0.18        15\n",
      "\n",
      "    accuracy                           0.49        70\n",
      "   macro avg       0.41      0.60      0.44        70\n",
      "weighted avg       0.62      0.49      0.53        70\n",
      "\n",
      "[id=151] MSE: 12730.292, R²: -12.142 x_train_count: 52\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         0          1\n",
      "True_mid          4         2          3\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.80      0.62         5\n",
      "         mid       1.00      0.22      0.36         9\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.50      0.34      0.33        14\n",
      "weighted avg       0.82      0.43      0.45        14\n",
      "\n",
      "[id=152] MSE: 535.540, R²: -1.938 x_train_count: 104\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          1         3          9\n",
      "True_good         0         4          9\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.43      0.23      0.30        13\n",
      "        good       0.50      0.69      0.58        13\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.31      0.31      0.29        26\n",
      "weighted avg       0.46      0.46      0.44        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.441e+02, tolerance: 1.227e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.212e+01, tolerance: 1.284e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=153] MSE: 6322.319, R²: -0.340 x_train_count: 434\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         72         3          2\n",
      "True_mid         13        15          3\n",
      "True_good         1         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.84      0.94      0.88        77\n",
      "         mid       0.83      0.48      0.61        31\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80       109\n",
      "   macro avg       0.56      0.47      0.50       109\n",
      "weighted avg       0.83      0.80      0.80       109\n",
      "\n",
      "[id=154] MSE: 1921.616, R²: -2.028 x_train_count: 88\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         1          2\n",
      "True_mid          5         6          6\n",
      "True_good         0         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.17      0.25      0.20         4\n",
      "         mid       0.75      0.35      0.48        17\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32        22\n",
      "   macro avg       0.31      0.20      0.23        22\n",
      "weighted avg       0.61      0.32      0.41        22\n",
      "\n",
      "[id=155] MSE: 3639.807, R²: -3.568 x_train_count: 144\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          3\n",
      "True_mid          3         9         14\n",
      "True_good         0         2          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      0.25      0.25         4\n",
      "         mid       0.82      0.35      0.49        26\n",
      "        good       0.23      0.71      0.34         7\n",
      "\n",
      "    accuracy                           0.41        37\n",
      "   macro avg       0.43      0.44      0.36        37\n",
      "weighted avg       0.64      0.41      0.43        37\n",
      "\n",
      "[id=156] MSE: 2211.477, R²: -0.464 x_train_count: 240\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          7         1          2\n",
      "True_mid          4         4          1\n",
      "True_good        14        13         14\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.28      0.70      0.40        10\n",
      "         mid       0.22      0.44      0.30         9\n",
      "        good       0.82      0.34      0.48        41\n",
      "\n",
      "    accuracy                           0.42        60\n",
      "   macro avg       0.44      0.50      0.39        60\n",
      "weighted avg       0.64      0.42      0.44        60\n",
      "\n",
      "[id=157] MSE: 1271.333, R²: -0.293 x_train_count: 61\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         1          2\n",
      "True_mid          2         1          3\n",
      "True_good         1         1          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.50      0.50         6\n",
      "         mid       0.33      0.17      0.22         6\n",
      "        good       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.38        16\n",
      "   macro avg       0.37      0.39      0.36        16\n",
      "weighted avg       0.38      0.38      0.36        16\n",
      "\n",
      "[id=159] MSE: 1836.033, R²: -2.566 x_train_count: 26\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         1          3\n",
      "True_mid          0         2          1\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         4\n",
      "         mid       0.67      0.67      0.67         3\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29         7\n",
      "   macro avg       0.22      0.22      0.22         7\n",
      "weighted avg       0.29      0.29      0.29         7\n",
      "\n",
      "[id=161] MSE: 731.047, R²: 0.112 x_train_count: 524\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1        11          4\n",
      "True_mid          1        15         23\n",
      "True_good         1        25         50\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.06      0.11        16\n",
      "         mid       0.29      0.38      0.33        39\n",
      "        good       0.65      0.66      0.65        76\n",
      "\n",
      "    accuracy                           0.50       131\n",
      "   macro avg       0.43      0.37      0.36       131\n",
      "weighted avg       0.50      0.50      0.49       131\n",
      "\n",
      "[id=162] MSE: 3523.115, R²: -7.852 x_train_count: 66\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          1\n",
      "True_mid          1         2          6\n",
      "True_good         0         0          7\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       1.00      0.22      0.36         9\n",
      "        good       0.50      1.00      0.67         7\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.50      0.41      0.34        17\n",
      "weighted avg       0.74      0.53      0.47        17\n",
      "\n",
      "[id=163] MSE: 258.474, R²: 0.000 x_train_count: 124\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          2        25          5\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.78      0.88        32\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.33      0.26      0.29        32\n",
      "weighted avg       1.00      0.78      0.88        32\n",
      "\n",
      "[id=165] MSE: 2465.285, R²: -2.580 x_train_count: 68\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          0\n",
      "True_mid          4         3          9\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.20      1.00      0.33         1\n",
      "         mid       1.00      0.19      0.32        16\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24        17\n",
      "   macro avg       0.40      0.40      0.22        17\n",
      "weighted avg       0.95      0.24      0.32        17\n",
      "\n",
      "[id=167] MSE: 458.529, R²: -0.542 x_train_count: 472\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         7          5\n",
      "True_mid          0        41         30\n",
      "True_good         0        22         12\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.14      0.25        14\n",
      "         mid       0.59      0.58      0.58        71\n",
      "        good       0.26      0.35      0.30        34\n",
      "\n",
      "    accuracy                           0.46       119\n",
      "   macro avg       0.61      0.36      0.38       119\n",
      "weighted avg       0.54      0.46      0.46       119\n",
      "\n",
      "[id=169] MSE: 0.000, R²: 1.000 x_train_count: 38\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0        10          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        10\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.33      0.33      0.33        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "[id=170] MSE: 1236.627, R²: 0.166 x_train_count: 464\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         7          8\n",
      "True_mid          0        15         24\n",
      "True_good         0        12         50\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        15\n",
      "         mid       0.44      0.38      0.41        39\n",
      "        good       0.61      0.81      0.69        62\n",
      "\n",
      "    accuracy                           0.56       116\n",
      "   macro avg       0.35      0.40      0.37       116\n",
      "weighted avg       0.47      0.56      0.51       116\n",
      "\n",
      "[id=171] MSE: 3206.817, R²: -0.991 x_train_count: 178\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         11         2          7\n",
      "True_mid          8         3          8\n",
      "True_good         2         2          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.52      0.55      0.54        20\n",
      "         mid       0.43      0.16      0.23        19\n",
      "        good       0.12      0.33      0.17         6\n",
      "\n",
      "    accuracy                           0.36        45\n",
      "   macro avg       0.36      0.35      0.31        45\n",
      "weighted avg       0.43      0.36      0.36        45\n",
      "\n",
      "[id=172] MSE: 0.000, R²: 0.000 x_train_count: 440\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0       111          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00       111\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       111\n",
      "   macro avg       0.33      0.33      0.33       111\n",
      "weighted avg       1.00      1.00      1.00       111\n",
      "\n",
      "[id=175] MSE: 3186.945, R²: -0.167 x_train_count: 267\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         21         7         11\n",
      "True_mid          5         9          9\n",
      "True_good         2         1          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.75      0.54      0.63        39\n",
      "         mid       0.53      0.39      0.45        23\n",
      "        good       0.09      0.40      0.15         5\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.46      0.44      0.41        67\n",
      "weighted avg       0.63      0.48      0.53        67\n",
      "\n",
      "[id=176] MSE: 2344.099, R²: -2.088 x_train_count: 102\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          1\n",
      "True_mid          6         2         14\n",
      "True_good         0         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      0.67      0.36         3\n",
      "         mid       0.67      0.09      0.16        22\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.15        26\n",
      "   macro avg       0.31      0.25      0.17        26\n",
      "weighted avg       0.59      0.15      0.18        26\n",
      "\n",
      "[id=177] MSE: 8683.890, R²: -3.677 x_train_count: 140\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6         5          1\n",
      "True_mid          2         5         11\n",
      "True_good         1         1          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.50      0.57        12\n",
      "         mid       0.45      0.28      0.34        18\n",
      "        good       0.25      0.67      0.36         6\n",
      "\n",
      "    accuracy                           0.42        36\n",
      "   macro avg       0.46      0.48      0.43        36\n",
      "weighted avg       0.49      0.42      0.42        36\n",
      "\n",
      "[id=179] MSE: 1796.411, R²: -3.227 x_train_count: 144\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          0\n",
      "True_mid          7         2          2\n",
      "True_good         8        10          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.12      1.00      0.21         2\n",
      "         mid       0.17      0.18      0.17        11\n",
      "        good       0.71      0.22      0.33        23\n",
      "\n",
      "    accuracy                           0.25        36\n",
      "   macro avg       0.33      0.47      0.24        36\n",
      "weighted avg       0.51      0.25      0.28        36\n",
      "\n",
      "[id=180] MSE: 2516.576, R²: -2.064 x_train_count: 83\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          0\n",
      "True_mid          2         3         13\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      1.00      0.67         2\n",
      "         mid       1.00      0.17      0.29        18\n",
      "        good       0.07      1.00      0.13         1\n",
      "\n",
      "    accuracy                           0.29        21\n",
      "   macro avg       0.52      0.72      0.36        21\n",
      "weighted avg       0.91      0.29      0.31        21\n",
      "\n",
      "[id=181] MSE: 14004.057, R²: -25.514 x_train_count: 167\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8         0          1\n",
      "True_mid         19         2          6\n",
      "True_good         5         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      0.89      0.39         9\n",
      "         mid       1.00      0.07      0.14        27\n",
      "        good       0.12      0.17      0.14         6\n",
      "\n",
      "    accuracy                           0.26        42\n",
      "   macro avg       0.46      0.38      0.22        42\n",
      "weighted avg       0.71      0.26      0.19        42\n",
      "\n",
      "[id=184] MSE: 4369.468, R²: -1.472 x_train_count: 340\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3        10         20\n",
      "True_mid          4         5         24\n",
      "True_good         0         2         17\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      0.09      0.15        33\n",
      "         mid       0.29      0.15      0.20        33\n",
      "        good       0.28      0.89      0.42        19\n",
      "\n",
      "    accuracy                           0.29        85\n",
      "   macro avg       0.33      0.38      0.26        85\n",
      "weighted avg       0.34      0.29      0.23        85\n",
      "\n",
      "[id=185] MSE: 1966.222, R²: -0.031 x_train_count: 156\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8         1          2\n",
      "True_mid          8         5          7\n",
      "True_good         5         4          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.38      0.73      0.50        11\n",
      "         mid       0.50      0.25      0.33        20\n",
      "        good       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.33        40\n",
      "   macro avg       0.29      0.33      0.28        40\n",
      "weighted avg       0.35      0.33      0.30        40\n",
      "\n",
      "[id=186] MSE: 1390.758, R²: -0.566 x_train_count: 312\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         4         11\n",
      "True_mid          0         5         25\n",
      "True_good         0         2         32\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        15\n",
      "         mid       0.45      0.17      0.24        30\n",
      "        good       0.47      0.94      0.63        34\n",
      "\n",
      "    accuracy                           0.47        79\n",
      "   macro avg       0.31      0.37      0.29        79\n",
      "weighted avg       0.38      0.47      0.36        79\n",
      "\n",
      "[id=187] MSE: 1969.719, R²: 0.042 x_train_count: 428\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         68         6          1\n",
      "True_mid         19         9          0\n",
      "True_good         5         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.74      0.91      0.81        75\n",
      "         mid       0.60      0.32      0.42        28\n",
      "        good       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.71       108\n",
      "   macro avg       0.45      0.41      0.41       108\n",
      "weighted avg       0.67      0.71      0.67       108\n",
      "\n",
      "[id=188] MSE: 1543.361, R²: -2.164 x_train_count: 147\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          6         2          1\n",
      "True_mid         12         7          2\n",
      "True_good         5         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.26      0.67      0.38         9\n",
      "         mid       0.70      0.33      0.45        21\n",
      "        good       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.38        37\n",
      "   macro avg       0.40      0.38      0.34        37\n",
      "weighted avg       0.51      0.38      0.38        37\n",
      "\n",
      "[id=189] MSE: 2141.223, R²: -0.709 x_train_count: 78\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         2          2\n",
      "True_mid          0         2          5\n",
      "True_good         0         4          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         4\n",
      "         mid       0.25      0.29      0.27         7\n",
      "        good       0.42      0.56      0.48         9\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.22      0.28      0.25        20\n",
      "weighted avg       0.28      0.35      0.31        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=190] MSE: 279.169, R²: 0.000 x_train_count: 31\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0         3          5\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.38      0.55         8\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.33      0.12      0.18         8\n",
      "weighted avg       1.00      0.38      0.55         8\n",
      "\n",
      "[id=192] MSE: 2548.836, R²: 0.018 x_train_count: 28\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         1          1\n",
      "True_mid          0         0          2\n",
      "True_good         0         2          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.33      0.50         3\n",
      "         mid       0.00      0.00      0.00         2\n",
      "        good       0.25      0.33      0.29         3\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.42      0.22      0.26         8\n",
      "weighted avg       0.47      0.25      0.29         8\n",
      "\n",
      "[id=193] MSE: 3746.598, R²: -5.909 x_train_count: 80\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          3         0          1\n",
      "True_mid          6         3          8\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.75      0.46         4\n",
      "         mid       1.00      0.18      0.30        17\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29        21\n",
      "   macro avg       0.44      0.31      0.25        21\n",
      "weighted avg       0.87      0.29      0.33        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e+02, tolerance: 8.544e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=195] MSE: 3767.784, R²: -1.128 x_train_count: 66\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          4         0          1\n",
      "True_mid          4         4          3\n",
      "True_good         1         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.44      0.80      0.57         5\n",
      "         mid       1.00      0.36      0.53        11\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.47        17\n",
      "   macro avg       0.48      0.39      0.37        17\n",
      "weighted avg       0.78      0.47      0.51        17\n",
      "\n",
      "[id=197] MSE: 1953.864, R²: -6.893 x_train_count: 28\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          2\n",
      "True_mid          0         1          3\n",
      "True_good         1         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       1.00      0.25      0.40         4\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.14         7\n",
      "   macro avg       0.33      0.08      0.13         7\n",
      "weighted avg       0.57      0.14      0.23         7\n",
      "\n",
      "[id=200] MSE: 1233.393, R²: -0.455 x_train_count: 120\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8         3          1\n",
      "True_mid          5         5          7\n",
      "True_good         0         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.67      0.64        12\n",
      "         mid       0.56      0.29      0.38        17\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.39      0.32      0.34        30\n",
      "weighted avg       0.56      0.43      0.47        30\n",
      "\n",
      "[id=202] MSE: 6738.002, R²: -7.852 x_train_count: 98\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          3\n",
      "True_mid          2         4         15\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       1.00      0.19      0.32        21\n",
      "        good       0.05      1.00      0.10         1\n",
      "\n",
      "    accuracy                           0.20        25\n",
      "   macro avg       0.35      0.40      0.14        25\n",
      "weighted avg       0.84      0.20      0.27        25\n",
      "\n",
      "[id=205] MSE: 2021.213, R²: 0.185 x_train_count: 208\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         15         2          2\n",
      "True_mid          8         7          3\n",
      "True_good         7         5          4\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.79      0.61        19\n",
      "         mid       0.50      0.39      0.44        18\n",
      "        good       0.44      0.25      0.32        16\n",
      "\n",
      "    accuracy                           0.49        53\n",
      "   macro avg       0.48      0.48      0.46        53\n",
      "weighted avg       0.48      0.49      0.46        53\n",
      "\n",
      "[id=207] MSE: 54.720, R²: -1.606 x_train_count: 45\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0         3          8\n",
      "True_good         0         0          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.27      0.43        11\n",
      "        good       0.11      1.00      0.20         1\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.37      0.42      0.21        12\n",
      "weighted avg       0.93      0.33      0.41        12\n",
      "\n",
      "[id=208] MSE: 3093.579, R²: -1.283 x_train_count: 146\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         18         3          1\n",
      "True_mid          8         3          2\n",
      "True_good         1         0          1\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.82      0.73        22\n",
      "         mid       0.50      0.23      0.32        13\n",
      "        good       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.59        37\n",
      "   macro avg       0.47      0.52      0.46        37\n",
      "weighted avg       0.59      0.59      0.57        37\n",
      "\n",
      "[id=209] MSE: 502.103, R²: -0.945 x_train_count: 214\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         4          4\n",
      "True_mid          2        22         11\n",
      "True_good         0         8          3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         8\n",
      "         mid       0.65      0.63      0.64        35\n",
      "        good       0.17      0.27      0.21        11\n",
      "\n",
      "    accuracy                           0.46        54\n",
      "   macro avg       0.27      0.30      0.28        54\n",
      "weighted avg       0.45      0.46      0.46        54\n",
      "\n",
      "[id=211] MSE: 0.000, R²: 1.000 x_train_count: 223\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0        56          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        56\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       0.33      0.33      0.33        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "[id=212] MSE: 4790.039, R²: -3.988 x_train_count: 218\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         10         5          2\n",
      "True_mid          9         5         12\n",
      "True_good         4         3          5\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      0.59      0.50        17\n",
      "         mid       0.38      0.19      0.26        26\n",
      "        good       0.26      0.42      0.32        12\n",
      "\n",
      "    accuracy                           0.36        55\n",
      "   macro avg       0.36      0.40      0.36        55\n",
      "weighted avg       0.37      0.36      0.35        55\n",
      "\n",
      "[id=214] MSE: 5009.177, R²: -3.332 x_train_count: 165\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          2         0          5\n",
      "True_mid          0         3         13\n",
      "True_good         1         0         18\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.29      0.40         7\n",
      "         mid       1.00      0.19      0.32        16\n",
      "        good       0.50      0.95      0.65        19\n",
      "\n",
      "    accuracy                           0.55        42\n",
      "   macro avg       0.72      0.47      0.46        42\n",
      "weighted avg       0.72      0.55      0.48        42\n",
      "\n",
      "[id=215] MSE: 2797.867, R²: -9.654 x_train_count: 95\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          2\n",
      "True_mid          1         7          9\n",
      "True_good         1         2          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.78      0.41      0.54        17\n",
      "        good       0.15      0.40      0.22         5\n",
      "\n",
      "    accuracy                           0.38        24\n",
      "   macro avg       0.31      0.27      0.25        24\n",
      "weighted avg       0.58      0.38      0.43        24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e+00, tolerance: 1.976e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+01, tolerance: 9.842e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id=216] MSE: 0.000, R²: 1.000 x_train_count: 246\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0        62          0\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        62\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        62\n",
      "   macro avg       0.33      0.33      0.33        62\n",
      "weighted avg       1.00      1.00      1.00        62\n",
      "\n",
      "[id=217] MSE: 8039.451, R²: -2.616 x_train_count: 198\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad         10         5          4\n",
      "True_mid         10         3          5\n",
      "True_good         9         4          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.34      0.53      0.42        19\n",
      "         mid       0.25      0.17      0.20        18\n",
      "        good       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.26        50\n",
      "   macro avg       0.20      0.23      0.21        50\n",
      "weighted avg       0.22      0.26      0.23        50\n",
      "\n",
      "[id=219] MSE: 2925.790, R²: -12.487 x_train_count: 84\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          1         0          0\n",
      "True_mid          2         3          8\n",
      "True_good         1         0          6\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      1.00      0.40         1\n",
      "         mid       1.00      0.23      0.38        13\n",
      "        good       0.43      0.86      0.57         7\n",
      "\n",
      "    accuracy                           0.48        21\n",
      "   macro avg       0.56      0.70      0.45        21\n",
      "weighted avg       0.77      0.48      0.44        21\n",
      "\n",
      "[id=220] MSE: 3264.355, R²: -9.484 x_train_count: 33\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         1          1\n",
      "True_mid          3         1          2\n",
      "True_good         0         1          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.33      0.17      0.22         6\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.11         9\n",
      "   macro avg       0.11      0.06      0.07         9\n",
      "weighted avg       0.22      0.11      0.15         9\n",
      "\n",
      "[id=221] MSE: 9169.623, R²: -227.823 x_train_count: 77\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          8         3          6\n",
      "True_good         1         1          1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.75      0.18      0.29        17\n",
      "        good       0.14      0.33      0.20         3\n",
      "\n",
      "    accuracy                           0.20        20\n",
      "   macro avg       0.30      0.17      0.16        20\n",
      "weighted avg       0.66      0.20      0.27        20\n",
      "\n",
      "[id=222] MSE: 3975.199, R²: -0.896 x_train_count: 123\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          8         1          5\n",
      "True_mid          5         2          3\n",
      "True_good         2         3          2\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.53      0.57      0.55        14\n",
      "         mid       0.33      0.20      0.25        10\n",
      "        good       0.20      0.29      0.24         7\n",
      "\n",
      "    accuracy                           0.39        31\n",
      "   macro avg       0.36      0.35      0.35        31\n",
      "weighted avg       0.39      0.39      0.38        31\n",
      "\n",
      "[id=223] MSE: 2365.329, R²: 0.000 x_train_count: 44\n",
      "Confusion Matrix:\n",
      "           Pred_bad  Pred_mid  Pred_good\n",
      "True_bad          0         0          0\n",
      "True_mid          0         4          8\n",
      "True_good         0         0          0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.33      0.50        12\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.33      0.11      0.17        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "for pid, group in filtered_data.groupby('patient_id'):\n",
    "\n",
    "    # feature / target 나누기\n",
    "    y = group['sleep_quality_score']\n",
    "    X = group.drop(columns=['sleep_quality_score', 'score_level', 'patient_id', 'timestamp'])\n",
    "    \n",
    "\n",
    "    # train/test split (시계열 고려해서 shuffle=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Lasso 모델 학습\n",
    "    model = Lasso(alpha=0.1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test) \n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'[id={pid}] MSE: {mse:.3f}, R²: {r2:.3f} x_train_count: {len(X_train)}')\n",
    "\n",
    "    y_test_pd = pd.DataFrame(y_test,columns=['sleep_quality_score'])\n",
    "    y_pred_pd = pd.DataFrame(y_pred,columns=['sleep_quality_score'])\n",
    "\n",
    "    \n",
    "    # 등급 부여\n",
    "    y_pred_pd['score_level'] = 'mid'\n",
    "    y_pred_pd.loc[y_pred_pd['sleep_quality_score'] >= threshold_high, 'score_level'] = 'good'\n",
    "    y_pred_pd.loc[y_pred_pd['sleep_quality_score'] <= threshold_low, 'score_level'] = 'bad'\n",
    "    \n",
    "    y_test_pd['score_level'] = 'mid'\n",
    "    y_test_pd.loc[y_test_pd['sleep_quality_score'] >= threshold_high, 'score_level'] = 'good'\n",
    "    y_test_pd.loc[y_test_pd['sleep_quality_score'] <= threshold_low, 'score_level'] = 'bad'\n",
    "    \n",
    "    # confusion matrix 계산\n",
    "    labels = ['bad', 'mid', 'good']  # 클래스 순서 정의\n",
    "    cm = confusion_matrix(y_test_pd['score_level'], y_pred_pd['score_level'], labels=labels)\n",
    "    \n",
    "    # DataFrame으로 보기 좋게 출력\n",
    "    cm_df = pd.DataFrame(cm, index=[f\"True_{l}\" for l in labels], columns=[f\"Pred_{l}\" for l in labels])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm_df)\n",
    "\n",
    "        # 성능 리포트 (정밀도, 재현율 등)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_pd['score_level'], y_pred_pd['score_level'], labels=labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
