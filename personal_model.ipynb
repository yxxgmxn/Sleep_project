{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "data = pd.read_csv('processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts = data['patient_id'].value_counts()\n",
    "patient_counts_pd = pd.DataFrame(patient_counts)\n",
    "patient_counts_pd = patient_counts_pd.loc[patient_counts_pd['count'] > 29]\n",
    "\n",
    "filtered_data = data[data['patient_id'].isin(patient_counts_pd.index)]  # 해당 ID만 남기기\n",
    "filtered_data.to_csv('filtered_id_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_high = 25.34 \n",
    "\n",
    "threshold_low = -2.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1]\n",
      " [ 8 71  4]\n",
      " [ 2  9  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.09      0.33      0.14         3\n",
      "         mid       0.88      0.86      0.87        83\n",
      "        good       0.55      0.35      0.43        17\n",
      "\n",
      "    accuracy                           0.76       103\n",
      "   macro avg       0.50      0.51      0.48       103\n",
      "weighted avg       0.80      0.76      0.77       103\n",
      "\n",
      "[[ 1  7 20]\n",
      " [ 5 51 60]\n",
      " [ 1 12 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.04      0.06        28\n",
      "         mid       0.73      0.44      0.55       116\n",
      "        good       0.49      0.85      0.62        89\n",
      "\n",
      "    accuracy                           0.55       233\n",
      "   macro avg       0.45      0.44      0.41       233\n",
      "weighted avg       0.57      0.55      0.52       233\n",
      "\n",
      "[[ 10  13   8]\n",
      " [ 19  45  39]\n",
      " [  1  58 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.32      0.33        31\n",
      "         mid       0.39      0.44      0.41       103\n",
      "        good       0.70      0.65      0.68       170\n",
      "\n",
      "    accuracy                           0.55       304\n",
      "   macro avg       0.47      0.47      0.47       304\n",
      "weighted avg       0.56      0.55      0.55       304\n",
      "\n",
      "[[21  8  3]\n",
      " [20 27  3]\n",
      " [ 1  4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.66      0.57        32\n",
      "         mid       0.69      0.54      0.61        50\n",
      "        good       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.40      0.40      0.39        87\n",
      "weighted avg       0.58      0.55      0.56        87\n",
      "\n",
      "[[ 6  9  7]\n",
      " [ 8 31 14]\n",
      " [ 2 21 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.38      0.27      0.32        22\n",
      "         mid       0.51      0.58      0.54        53\n",
      "        good       0.66      0.63      0.65        63\n",
      "\n",
      "    accuracy                           0.56       138\n",
      "   macro avg       0.51      0.50      0.50       138\n",
      "weighted avg       0.55      0.56      0.55       138\n",
      "\n",
      "[[ 0  2 15]\n",
      " [ 1 52 21]\n",
      " [ 0  3 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        17\n",
      "         mid       0.91      0.70      0.79        74\n",
      "        good       0.71      0.97      0.82        93\n",
      "\n",
      "    accuracy                           0.77       184\n",
      "   macro avg       0.54      0.56      0.54       184\n",
      "weighted avg       0.73      0.77      0.73       184\n",
      "\n",
      "[[ 6 11  1]\n",
      " [20 38  3]\n",
      " [ 8 10  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.18      0.33      0.23        18\n",
      "         mid       0.64      0.62      0.63        61\n",
      "        good       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.48       101\n",
      "   macro avg       0.44      0.38      0.38       101\n",
      "weighted avg       0.53      0.48      0.48       101\n",
      "\n",
      "[[ 6  6  6]\n",
      " [ 0 12  6]\n",
      " [ 0  2  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.33      0.50        18\n",
      "         mid       0.60      0.67      0.63        18\n",
      "        good       0.08      0.33      0.12         3\n",
      "\n",
      "    accuracy                           0.49        39\n",
      "   macro avg       0.56      0.44      0.42        39\n",
      "weighted avg       0.74      0.49      0.53        39\n",
      "\n",
      "[[ 2 17 14]\n",
      " [ 3 42 15]\n",
      " [ 1  6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.06      0.10        33\n",
      "         mid       0.65      0.70      0.67        60\n",
      "        good       0.43      0.76      0.55        29\n",
      "\n",
      "    accuracy                           0.54       122\n",
      "   macro avg       0.47      0.51      0.44       122\n",
      "weighted avg       0.51      0.54      0.49       122\n",
      "\n",
      "[[ 0  2  1]\n",
      " [ 9 31 48]\n",
      " [ 4 23 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.55      0.35      0.43        88\n",
      "        good       0.62      0.75      0.68       106\n",
      "\n",
      "    accuracy                           0.56       197\n",
      "   macro avg       0.39      0.37      0.37       197\n",
      "weighted avg       0.58      0.56      0.56       197\n",
      "\n",
      "[[ 6  7  5]\n",
      " [ 2 44  5]\n",
      " [ 1  5  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.33      0.44        18\n",
      "         mid       0.79      0.86      0.82        51\n",
      "        good       0.33      0.45      0.38        11\n",
      "\n",
      "    accuracy                           0.69        80\n",
      "   macro avg       0.60      0.55      0.55        80\n",
      "weighted avg       0.70      0.69      0.68        80\n",
      "\n",
      "[[ 30  64   1]\n",
      " [ 14 140   5]\n",
      " [  3  35   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.64      0.32      0.42        95\n",
      "         mid       0.59      0.88      0.70       159\n",
      "        good       0.57      0.17      0.27        46\n",
      "\n",
      "    accuracy                           0.59       300\n",
      "   macro avg       0.60      0.46      0.46       300\n",
      "weighted avg       0.60      0.59      0.55       300\n",
      "\n",
      "[[ 2  0  1]\n",
      " [ 1  1 14]\n",
      " [ 0  2 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.67      0.67         3\n",
      "         mid       0.33      0.06      0.11        16\n",
      "        good       0.50      0.88      0.64        17\n",
      "\n",
      "    accuracy                           0.50        36\n",
      "   macro avg       0.50      0.54      0.47        36\n",
      "weighted avg       0.44      0.50      0.40        36\n",
      "\n",
      "[[ 33  62   2]\n",
      " [ 24 126   5]\n",
      " [  6  41   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.52      0.34      0.41        97\n",
      "         mid       0.55      0.81      0.66       155\n",
      "        good       0.56      0.16      0.25        56\n",
      "\n",
      "    accuracy                           0.55       308\n",
      "   macro avg       0.55      0.44      0.44       308\n",
      "weighted avg       0.54      0.55      0.51       308\n",
      "\n",
      "[[  2   1   9]\n",
      " [  2  15  32]\n",
      " [  8  23 171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.17      0.17      0.17        12\n",
      "         mid       0.38      0.31      0.34        49\n",
      "        good       0.81      0.85      0.83       202\n",
      "\n",
      "    accuracy                           0.71       263\n",
      "   macro avg       0.45      0.44      0.44       263\n",
      "weighted avg       0.70      0.71      0.71       263\n",
      "\n",
      "[[23 11 12]\n",
      " [ 5 58 17]\n",
      " [ 7 11  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.66      0.50      0.57        46\n",
      "         mid       0.72      0.72      0.72        80\n",
      "        good       0.24      0.33      0.28        27\n",
      "\n",
      "    accuracy                           0.59       153\n",
      "   macro avg       0.54      0.52      0.52       153\n",
      "weighted avg       0.62      0.59      0.60       153\n",
      "\n",
      "[[14  4  2]\n",
      " [12 55  6]\n",
      " [19  6  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.31      0.70      0.43        20\n",
      "         mid       0.85      0.75      0.80        73\n",
      "        good       0.27      0.11      0.15        28\n",
      "\n",
      "    accuracy                           0.60       121\n",
      "   macro avg       0.48      0.52      0.46       121\n",
      "weighted avg       0.63      0.60      0.59       121\n",
      "\n",
      "[[40  6  3]\n",
      " [ 9  4  0]\n",
      " [ 3  2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.77      0.82      0.79        49\n",
      "         mid       0.33      0.31      0.32        13\n",
      "        good       0.40      0.29      0.33         7\n",
      "\n",
      "    accuracy                           0.67        69\n",
      "   macro avg       0.50      0.47      0.48        69\n",
      "weighted avg       0.65      0.67      0.66        69\n",
      "\n",
      "[[ 26  29   0]\n",
      " [  7 156   0]\n",
      " [  1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.76      0.47      0.58        55\n",
      "         mid       0.84      0.96      0.90       163\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83       219\n",
      "   macro avg       0.54      0.48      0.49       219\n",
      "weighted avg       0.82      0.83      0.81       219\n",
      "\n",
      "[[ 9 10  0]\n",
      " [ 9 42  0]\n",
      " [ 1  5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.47      0.47      0.47        19\n",
      "         mid       0.74      0.82      0.78        51\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.67        76\n",
      "   macro avg       0.40      0.43      0.42        76\n",
      "weighted avg       0.61      0.67      0.64        76\n",
      "\n",
      "[[ 2  2  2]\n",
      " [ 1 17  2]\n",
      " [ 1  5  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.33      0.40         6\n",
      "         mid       0.71      0.85      0.77        20\n",
      "        good       0.67      0.57      0.62        14\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.62      0.58      0.60        40\n",
      "weighted avg       0.66      0.68      0.66        40\n",
      "\n",
      "[[42 24 11]\n",
      " [18 58  3]\n",
      " [ 4 21  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.66      0.55      0.60        77\n",
      "         mid       0.56      0.73      0.64        79\n",
      "        good       0.12      0.07      0.09        27\n",
      "\n",
      "    accuracy                           0.56       183\n",
      "   macro avg       0.45      0.45      0.44       183\n",
      "weighted avg       0.54      0.56      0.54       183\n",
      "\n",
      "[[ 4  4  3]\n",
      " [ 6 45  4]\n",
      " [ 5 18  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.27      0.36      0.31        11\n",
      "         mid       0.67      0.82      0.74        55\n",
      "        good       0.42      0.18      0.25        28\n",
      "\n",
      "    accuracy                           0.57        94\n",
      "   macro avg       0.45      0.45      0.43        94\n",
      "weighted avg       0.55      0.57      0.54        94\n",
      "\n",
      "[[ 9  6  2]\n",
      " [ 7 70  8]\n",
      " [ 6 14 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.41      0.53      0.46        17\n",
      "         mid       0.78      0.82      0.80        85\n",
      "        good       0.60      0.43      0.50        35\n",
      "\n",
      "    accuracy                           0.69       137\n",
      "   macro avg       0.60      0.59      0.59       137\n",
      "weighted avg       0.69      0.69      0.68       137\n",
      "\n",
      "[[ 4 10  2]\n",
      " [ 6 24  2]\n",
      " [ 2  4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.25      0.29        16\n",
      "         mid       0.63      0.75      0.69        32\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.52        54\n",
      "   macro avg       0.32      0.33      0.32        54\n",
      "weighted avg       0.47      0.52      0.49        54\n",
      "\n",
      "[[ 2  3  0]\n",
      " [ 0 62  0]\n",
      " [ 0  4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.40      0.57         5\n",
      "         mid       0.90      1.00      0.95        62\n",
      "        good       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.90        71\n",
      "   macro avg       0.63      0.47      0.51        71\n",
      "weighted avg       0.86      0.90      0.87        71\n",
      "\n",
      "[[ 1  3  0]\n",
      " [ 0 22  4]\n",
      " [ 0  7  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.25      0.40         4\n",
      "         mid       0.69      0.85      0.76        26\n",
      "        good       0.20      0.12      0.15         8\n",
      "\n",
      "    accuracy                           0.63        38\n",
      "   macro avg       0.63      0.41      0.44        38\n",
      "weighted avg       0.62      0.63      0.59        38\n",
      "\n",
      "[[13  9  0]\n",
      " [13 27  4]\n",
      " [ 7 15  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.39      0.59      0.47        22\n",
      "         mid       0.53      0.61      0.57        44\n",
      "        good       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.45        88\n",
      "   macro avg       0.31      0.40      0.35        88\n",
      "weighted avg       0.36      0.45      0.40        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 1]\n",
      " [2 5 1]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.20      0.25         5\n",
      "         mid       0.62      0.62      0.62         8\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.32      0.27      0.29        13\n",
      "weighted avg       0.51      0.46      0.48        13\n",
      "\n",
      "[[3 1 3]\n",
      " [1 5 1]\n",
      " [0 2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.75      0.43      0.55         7\n",
      "         mid       0.62      0.71      0.67         7\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.46      0.38      0.40        16\n",
      "weighted avg       0.60      0.50      0.53        16\n",
      "\n",
      "[[96  3  2]\n",
      " [ 4 71  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.96      0.95      0.96       101\n",
      "         mid       0.96      0.95      0.95        75\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95       176\n",
      "   macro avg       0.64      0.63      0.64       176\n",
      "weighted avg       0.96      0.95      0.95       176\n",
      "\n",
      "[[ 2  8  4]\n",
      " [ 0 37 24]\n",
      " [ 1  8  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.14      0.24        14\n",
      "         mid       0.70      0.61      0.65        61\n",
      "        good       0.15      0.36      0.21        14\n",
      "\n",
      "    accuracy                           0.49        89\n",
      "   macro avg       0.51      0.37      0.37        89\n",
      "weighted avg       0.61      0.49      0.52        89\n",
      "\n",
      "[[0 0 0]\n",
      " [0 8 0]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00         8\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  1]\n",
      " [ 3 51  5]\n",
      " [ 1 13  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.43      0.50        14\n",
      "         mid       0.72      0.86      0.78        59\n",
      "        good       0.40      0.22      0.29        18\n",
      "\n",
      "    accuracy                           0.67        91\n",
      "   macro avg       0.57      0.51      0.52        91\n",
      "weighted avg       0.64      0.67      0.64        91\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        18\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       0.33      0.33      0.33        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "[[ 5  2  2]\n",
      " [ 4 19  1]\n",
      " [ 1  2  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.56      0.53         9\n",
      "         mid       0.83      0.79      0.81        24\n",
      "        good       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.72        43\n",
      "   macro avg       0.68      0.68      0.68        43\n",
      "weighted avg       0.73      0.72      0.72        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  5  4]\n",
      " [13 43 16]\n",
      " [33 60 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.06      0.25      0.10        12\n",
      "         mid       0.40      0.60      0.48        72\n",
      "        good       0.67      0.31      0.42       134\n",
      "\n",
      "    accuracy                           0.40       218\n",
      "   macro avg       0.38      0.38      0.33       218\n",
      "weighted avg       0.55      0.40      0.42       218\n",
      "\n",
      "[[ 5 20  2]\n",
      " [ 4 47  6]\n",
      " [ 1 64  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.19      0.27        27\n",
      "         mid       0.36      0.82      0.50        57\n",
      "        good       0.27      0.04      0.08        68\n",
      "\n",
      "    accuracy                           0.36       152\n",
      "   macro avg       0.38      0.35      0.28       152\n",
      "weighted avg       0.35      0.36      0.27       152\n",
      "\n",
      "[[83  5  1]\n",
      " [ 0 59  0]\n",
      " [ 0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.93      0.97        89\n",
      "         mid       0.92      1.00      0.96        59\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96       148\n",
      "   macro avg       0.64      0.64      0.64       148\n",
      "weighted avg       0.97      0.96      0.96       148\n",
      "\n",
      "[[ 2  3  2]\n",
      " [ 7 28  6]\n",
      " [ 4  4 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.15      0.29      0.20         7\n",
      "         mid       0.80      0.68      0.74        41\n",
      "        good       0.71      0.71      0.71        28\n",
      "\n",
      "    accuracy                           0.66        76\n",
      "   macro avg       0.56      0.56      0.55        76\n",
      "weighted avg       0.71      0.66      0.68        76\n",
      "\n",
      "[[66 22  6]\n",
      " [40 42  8]\n",
      " [ 4  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.70      0.65        94\n",
      "         mid       0.66      0.47      0.55        90\n",
      "        good       0.07      0.20      0.10         5\n",
      "\n",
      "    accuracy                           0.58       189\n",
      "   macro avg       0.44      0.46      0.43       189\n",
      "weighted avg       0.61      0.58      0.58       189\n",
      "\n",
      "[[4 2 3]\n",
      " [1 8 1]\n",
      " [1 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.44      0.53         9\n",
      "         mid       0.80      0.80      0.80        10\n",
      "        good       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.60      0.64      0.59        22\n",
      "weighted avg       0.68      0.64      0.64        22\n",
      "\n",
      "[[ 4  3  2]\n",
      " [ 1 10  5]\n",
      " [ 0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.80      0.44      0.57         9\n",
      "         mid       0.67      0.62      0.65        16\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.49      0.36      0.41        27\n",
      "weighted avg       0.66      0.52      0.57        27\n",
      "\n",
      "[[ 0  1  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.92      1.00      0.96        11\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.31      0.33      0.32        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.93      0.93      0.93        15\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.31      0.31      0.31        16\n",
      "weighted avg       0.88      0.88      0.88        16\n",
      "\n",
      "[[ 7  2  0]\n",
      " [16 13  6]\n",
      " [ 5  6  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      0.78      0.38         9\n",
      "         mid       0.62      0.37      0.46        35\n",
      "        good       0.14      0.08      0.11        12\n",
      "\n",
      "    accuracy                           0.38        56\n",
      "   macro avg       0.34      0.41      0.32        56\n",
      "weighted avg       0.46      0.38      0.37        56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61  7  0]\n",
      " [19 47  0]\n",
      " [ 1  3  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.75      0.90      0.82        68\n",
      "         mid       0.82      0.71      0.76        66\n",
      "        good       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78       138\n",
      "   macro avg       0.53      0.54      0.53       138\n",
      "weighted avg       0.77      0.78      0.77       138\n",
      "\n",
      "[[ 8  5  1]\n",
      " [12 42 17]\n",
      " [ 0  1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.40      0.57      0.47        14\n",
      "         mid       0.88      0.59      0.71        71\n",
      "        good       0.14      0.75      0.24         4\n",
      "\n",
      "    accuracy                           0.60        89\n",
      "   macro avg       0.47      0.64      0.47        89\n",
      "weighted avg       0.77      0.60      0.65        89\n",
      "\n",
      "[[0 7 0]\n",
      " [2 4 0]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         7\n",
      "         mid       0.36      0.67      0.47         6\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.31        13\n",
      "   macro avg       0.12      0.22      0.16        13\n",
      "weighted avg       0.17      0.31      0.22        13\n",
      "\n",
      "[[0 2 0]\n",
      " [0 2 1]\n",
      " [0 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.40      0.67      0.50         3\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.13      0.22      0.17         6\n",
      "weighted avg       0.20      0.33      0.25         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  0]\n",
      " [ 0 24  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.96      1.00      0.98        24\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96        25\n",
      "   macro avg       0.32      0.33      0.33        25\n",
      "weighted avg       0.92      0.96      0.94        25\n",
      "\n",
      "[[ 0  1  1]\n",
      " [ 3  9 16]\n",
      " [ 0  7  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.53      0.32      0.40        28\n",
      "        good       0.15      0.30      0.20        10\n",
      "\n",
      "    accuracy                           0.30        40\n",
      "   macro avg       0.23      0.21      0.20        40\n",
      "weighted avg       0.41      0.30      0.33        40\n",
      "\n",
      "[[ 2  1  1]\n",
      " [ 0 12  1]\n",
      " [ 1  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.50      0.57         4\n",
      "         mid       0.80      0.92      0.86        13\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.49      0.47      0.48        20\n",
      "weighted avg       0.65      0.70      0.67        20\n",
      "\n",
      "[[ 0  1  0]\n",
      " [ 1 10  2]\n",
      " [ 0  3  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.71      0.77      0.74        13\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.24      0.26      0.25        17\n",
      "weighted avg       0.55      0.59      0.57        17\n",
      "\n",
      "[[  6  14   4]\n",
      " [ 14 137  16]\n",
      " [  2  14   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.27      0.25      0.26        24\n",
      "         mid       0.83      0.82      0.83       167\n",
      "        good       0.23      0.27      0.25        22\n",
      "\n",
      "    accuracy                           0.70       213\n",
      "   macro avg       0.44      0.45      0.45       213\n",
      "weighted avg       0.71      0.70      0.70       213\n",
      "\n",
      "[[ 0  9  1]\n",
      " [ 0 14  1]\n",
      " [ 0  6  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        10\n",
      "         mid       0.48      0.93      0.64        15\n",
      "        good       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.27      0.36      0.28        32\n",
      "weighted avg       0.30      0.47      0.34        32\n",
      "\n",
      "[[0 1 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.71      1.00      0.83         5\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.24      0.33      0.28         7\n",
      "weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 12  2]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.86      0.92        14\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.33      0.29      0.31        14\n",
      "weighted avg       1.00      0.86      0.92        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  0]\n",
      " [ 2 13  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.50      0.50         4\n",
      "         mid       0.87      0.87      0.87        15\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79        19\n",
      "   macro avg       0.46      0.46      0.46        19\n",
      "weighted avg       0.79      0.79      0.79        19\n",
      "\n",
      "[[0 3 1]\n",
      " [3 4 6]\n",
      " [2 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         4\n",
      "         mid       0.57      0.31      0.40        13\n",
      "        good       0.50      0.78      0.61         9\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.36      0.36      0.34        26\n",
      "weighted avg       0.46      0.42      0.41        26\n",
      "\n",
      "[[ 9  6  4]\n",
      " [ 3 51  7]\n",
      " [ 3  2 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.47      0.53        19\n",
      "         mid       0.86      0.84      0.85        61\n",
      "        good       0.54      0.72      0.62        18\n",
      "\n",
      "    accuracy                           0.74        98\n",
      "   macro avg       0.67      0.68      0.67        98\n",
      "weighted avg       0.75      0.74      0.75        98\n",
      "\n",
      "[[ 0  1  5]\n",
      " [ 3 28  3]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         6\n",
      "         mid       0.97      0.82      0.89        34\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.32      0.27      0.30        40\n",
      "weighted avg       0.82      0.70      0.76        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 11  7]\n",
      " [ 5  5  4]\n",
      " [ 1  2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.25      0.33        24\n",
      "         mid       0.28      0.36      0.31        14\n",
      "        good       0.15      0.40      0.22         5\n",
      "\n",
      "    accuracy                           0.30        43\n",
      "   macro avg       0.31      0.34      0.29        43\n",
      "weighted avg       0.39      0.30      0.31        43\n",
      "\n",
      "[[ 2  7  0]\n",
      " [ 0 27  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.22      0.36         9\n",
      "         mid       0.77      1.00      0.87        27\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78        37\n",
      "   macro avg       0.59      0.41      0.41        37\n",
      "weighted avg       0.81      0.78      0.72        37\n",
      "\n",
      "[[ 1  0  2]\n",
      " [ 0 33 10]\n",
      " [ 0  4  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.33      0.50         3\n",
      "         mid       0.89      0.77      0.82        43\n",
      "        good       0.20      0.43      0.27         7\n",
      "\n",
      "    accuracy                           0.70        53\n",
      "   macro avg       0.70      0.51      0.53        53\n",
      "weighted avg       0.81      0.70      0.73        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 40  0]\n",
      " [19 87  0]\n",
      " [ 3  5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.55      0.40      0.47        67\n",
      "         mid       0.66      0.82      0.73       106\n",
      "        good       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.63       181\n",
      "   macro avg       0.40      0.41      0.40       181\n",
      "weighted avg       0.59      0.63      0.60       181\n",
      "\n",
      "[[ 0  3  2]\n",
      " [ 0 12  7]\n",
      " [ 0  4 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         5\n",
      "         mid       0.63      0.63      0.63        19\n",
      "        good       0.55      0.73      0.63        15\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.39      0.45      0.42        39\n",
      "weighted avg       0.52      0.59      0.55        39\n",
      "\n",
      "[[ 2  7  2]\n",
      " [ 8 25 10]\n",
      " [ 1 12 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.18      0.18      0.18        11\n",
      "         mid       0.57      0.58      0.57        43\n",
      "        good       0.83      0.82      0.83        73\n",
      "\n",
      "    accuracy                           0.69       127\n",
      "   macro avg       0.53      0.53      0.53       127\n",
      "weighted avg       0.69      0.69      0.69       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64  5  2]\n",
      " [15 18  2]\n",
      " [ 2  4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.79      0.90      0.84        71\n",
      "         mid       0.67      0.51      0.58        35\n",
      "        good       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.73       112\n",
      "   macro avg       0.49      0.47      0.47       112\n",
      "weighted avg       0.71      0.73      0.72       112\n",
      "\n",
      "[[ 5  4 11]\n",
      " [ 5 28 23]\n",
      " [ 4  9 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.36      0.25      0.29        20\n",
      "         mid       0.68      0.50      0.58        56\n",
      "        good       0.47      0.70      0.56        43\n",
      "\n",
      "    accuracy                           0.53       119\n",
      "   macro avg       0.50      0.48      0.48       119\n",
      "weighted avg       0.55      0.53      0.52       119\n",
      "\n",
      "[[ 5  9  0]\n",
      " [ 9 41 16]\n",
      " [10 43 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.21      0.36      0.26        14\n",
      "         mid       0.44      0.62      0.52        66\n",
      "        good       0.64      0.35      0.46        82\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.43      0.44      0.41       162\n",
      "weighted avg       0.52      0.46      0.46       162\n",
      "\n",
      "[[0 1 1]\n",
      " [3 3 0]\n",
      " [3 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.75      0.50      0.60         6\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.27        11\n",
      "   macro avg       0.25      0.17      0.20        11\n",
      "weighted avg       0.41      0.27      0.33        11\n",
      "\n",
      "[[0 3 2]\n",
      " [2 6 3]\n",
      " [0 4 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         5\n",
      "         mid       0.46      0.55      0.50        11\n",
      "        good       0.17      0.20      0.18         5\n",
      "\n",
      "    accuracy                           0.33        21\n",
      "   macro avg       0.21      0.25      0.23        21\n",
      "weighted avg       0.28      0.33      0.31        21\n",
      "\n",
      "[[ 0  5  0]\n",
      " [ 0 12  0]\n",
      " [ 0  3  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         5\n",
      "         mid       0.60      1.00      0.75        12\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.20      0.33      0.25        20\n",
      "weighted avg       0.36      0.60      0.45        20\n",
      "\n",
      "[[ 5 12  9]\n",
      " [ 2 23 21]\n",
      " [ 0 15 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.71      0.19      0.30        26\n",
      "         mid       0.46      0.50      0.48        46\n",
      "        good       0.25      0.40      0.31        25\n",
      "\n",
      "    accuracy                           0.39        97\n",
      "   macro avg       0.47      0.36      0.36        97\n",
      "weighted avg       0.47      0.39      0.39        97\n",
      "\n",
      "[[ 5  3  1]\n",
      " [ 2 38  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.71      0.56      0.62         9\n",
      "         mid       0.90      0.95      0.93        40\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.54      0.50      0.52        50\n",
      "weighted avg       0.85      0.86      0.85        50\n",
      "\n",
      "[[2 0 0]\n",
      " [0 4 0]\n",
      " [0 2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         2\n",
      "         mid       0.67      1.00      0.80         4\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.56      0.67      0.60         8\n",
      "weighted avg       0.58      0.75      0.65         8\n",
      "\n",
      "[[9 4 0]\n",
      " [1 2 0]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.90      0.69      0.78        13\n",
      "         mid       0.33      0.67      0.44         3\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.41      0.45      0.41        16\n",
      "weighted avg       0.79      0.69      0.72        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  1]\n",
      " [ 1 43  0]\n",
      " [ 0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.80      0.80      0.80         5\n",
      "         mid       0.96      0.98      0.97        44\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        51\n",
      "   macro avg       0.59      0.59      0.59        51\n",
      "weighted avg       0.90      0.92      0.91        51\n",
      "\n",
      "[[ 2  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         2\n",
      "         mid       1.00      1.00      1.00        15\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        17\n",
      "   macro avg       0.67      0.67      0.67        17\n",
      "weighted avg       1.00      1.00      1.00        17\n",
      "\n",
      "[[0 0 0]\n",
      " [1 4 7]\n",
      " [1 2 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.67      0.33      0.44        12\n",
      "        good       0.12      0.25      0.17         4\n",
      "\n",
      "    accuracy                           0.31        16\n",
      "   macro avg       0.26      0.19      0.20        16\n",
      "weighted avg       0.53      0.31      0.38        16\n",
      "\n",
      "[[ 3  3  3]\n",
      " [ 8 32  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.27      0.33      0.30         9\n",
      "         mid       0.89      0.80      0.84        40\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.39      0.38      0.38        50\n",
      "weighted avg       0.76      0.70      0.73        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  7 24]\n",
      " [10 32 27]\n",
      " [13 12 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.18      0.14      0.16        36\n",
      "         mid       0.63      0.46      0.53        69\n",
      "        good       0.47      0.64      0.54        70\n",
      "\n",
      "    accuracy                           0.47       175\n",
      "   macro avg       0.42      0.42      0.41       175\n",
      "weighted avg       0.47      0.47      0.46       175\n",
      "\n",
      "[[ 4  6  8]\n",
      " [ 3 25 32]\n",
      " [ 3  3 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.40      0.22      0.29        18\n",
      "         mid       0.74      0.42      0.53        60\n",
      "        good       0.54      0.89      0.67        53\n",
      "\n",
      "    accuracy                           0.58       131\n",
      "   macro avg       0.56      0.51      0.50       131\n",
      "weighted avg       0.61      0.58      0.55       131\n",
      "\n",
      "[[22  2  1]\n",
      " [ 4 35  0]\n",
      " [ 0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.85      0.88      0.86        25\n",
      "         mid       0.95      0.90      0.92        39\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89        64\n",
      "   macro avg       0.60      0.59      0.59        64\n",
      "weighted avg       0.91      0.89      0.90        64\n",
      "\n",
      "[[17 42  4]\n",
      " [ 3 23 14]\n",
      " [ 1  1  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.81      0.27      0.40        63\n",
      "         mid       0.35      0.57      0.43        40\n",
      "        good       0.28      0.78      0.41         9\n",
      "\n",
      "    accuracy                           0.42       112\n",
      "   macro avg       0.48      0.54      0.42       112\n",
      "weighted avg       0.60      0.42      0.42       112\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  3  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.81      0.87      0.84        15\n",
      "        good       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.49      0.48      0.48        22\n",
      "weighted avg       0.77      0.77      0.77        22\n",
      "\n",
      "[[ 2  5  0]\n",
      " [ 5 16  0]\n",
      " [ 0  3  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.29      0.29      0.29         7\n",
      "         mid       0.67      0.76      0.71        21\n",
      "        good       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.58        31\n",
      "   macro avg       0.32      0.35      0.33        31\n",
      "weighted avg       0.52      0.58      0.55        31\n",
      "\n",
      "[[ 7  2  5]\n",
      " [15 26  8]\n",
      " [14  4 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.19      0.50      0.28        14\n",
      "         mid       0.81      0.53      0.64        49\n",
      "        good       0.46      0.38      0.42        29\n",
      "\n",
      "    accuracy                           0.48        92\n",
      "   macro avg       0.49      0.47      0.45        92\n",
      "weighted avg       0.61      0.48      0.52        92\n",
      "\n",
      "[[ 0  4  2]\n",
      " [ 1  7  4]\n",
      " [ 2  4 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         6\n",
      "         mid       0.47      0.58      0.52        12\n",
      "        good       0.68      0.68      0.68        19\n",
      "\n",
      "    accuracy                           0.54        37\n",
      "   macro avg       0.38      0.42      0.40        37\n",
      "weighted avg       0.50      0.54      0.52        37\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 0 23  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         1\n",
      "         mid       1.00      1.00      1.00        23\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       0.67      0.67      0.67        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n",
      "[[4 2 1]\n",
      " [2 7 7]\n",
      " [1 4 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.57      0.57      0.57         7\n",
      "         mid       0.54      0.44      0.48        16\n",
      "        good       0.11      0.17      0.13         6\n",
      "\n",
      "    accuracy                           0.41        29\n",
      "   macro avg       0.41      0.39      0.40        29\n",
      "weighted avg       0.46      0.41      0.43        29\n",
      "\n",
      "[[ 0  1  6]\n",
      " [ 2 14 34]\n",
      " [ 0 10 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         7\n",
      "         mid       0.56      0.28      0.37        50\n",
      "        good       0.68      0.89      0.77        95\n",
      "\n",
      "    accuracy                           0.65       152\n",
      "   macro avg       0.41      0.39      0.38       152\n",
      "weighted avg       0.61      0.65      0.61       152\n",
      "\n",
      "[[ 1  1  1]\n",
      " [ 0 10  2]\n",
      " [ 0  2  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.33      0.50         3\n",
      "         mid       0.77      0.83      0.80        12\n",
      "        good       0.57      0.67      0.62         6\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.78      0.61      0.64        21\n",
      "weighted avg       0.75      0.71      0.70        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  4]\n",
      " [ 0 30  1]\n",
      " [ 0  0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.17      0.29         6\n",
      "         mid       0.97      0.97      0.97        31\n",
      "        good       0.50      1.00      0.67         5\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.82      0.71      0.64        42\n",
      "weighted avg       0.92      0.86      0.83        42\n",
      "\n",
      "[[ 6 13  5]\n",
      " [12 37  7]\n",
      " [ 6  8  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      0.25      0.25        24\n",
      "         mid       0.64      0.66      0.65        56\n",
      "        good       0.14      0.12      0.13        16\n",
      "\n",
      "    accuracy                           0.47        96\n",
      "   macro avg       0.34      0.35      0.34        96\n",
      "weighted avg       0.46      0.47      0.46        96\n",
      "\n",
      "[[12 16  7]\n",
      " [ 4 44  3]\n",
      " [ 5  7  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.57      0.34      0.43        35\n",
      "         mid       0.66      0.86      0.75        51\n",
      "        good       0.23      0.20      0.21        15\n",
      "\n",
      "    accuracy                           0.58       101\n",
      "   macro avg       0.49      0.47      0.46       101\n",
      "weighted avg       0.56      0.58      0.56       101\n",
      "\n",
      "[[172   4   1]\n",
      " [  0   0   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.97      0.99       177\n",
      "         mid       0.00      0.00      0.00         0\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97       177\n",
      "   macro avg       0.33      0.32      0.33       177\n",
      "weighted avg       1.00      0.97      0.99       177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  8]\n",
      " [ 3 28  5]\n",
      " [ 2  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.29      0.17      0.21        12\n",
      "         mid       0.88      0.78      0.82        36\n",
      "        good       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.58        52\n",
      "   macro avg       0.39      0.31      0.34        52\n",
      "weighted avg       0.67      0.58      0.62        52\n",
      "\n",
      "[[ 7 14  5]\n",
      " [ 5 43  0]\n",
      " [ 2  5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.27      0.35        26\n",
      "         mid       0.69      0.90      0.78        48\n",
      "        good       0.17      0.12      0.14         8\n",
      "\n",
      "    accuracy                           0.62        82\n",
      "   macro avg       0.45      0.43      0.42        82\n",
      "weighted avg       0.58      0.62      0.58        82\n",
      "\n",
      "[[ 7  3  2]\n",
      " [ 2 16  1]\n",
      " [ 1  2  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.70      0.58      0.64        12\n",
      "         mid       0.76      0.84      0.80        19\n",
      "        good       0.25      0.25      0.25         4\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.57      0.56      0.56        35\n",
      "weighted avg       0.68      0.69      0.68        35\n",
      "\n",
      "[[ 4  0  0]\n",
      " [ 2 12  0]\n",
      " [ 0  4  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      1.00      0.80         4\n",
      "         mid       0.75      0.86      0.80        14\n",
      "        good       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.81      0.69      0.64        23\n",
      "weighted avg       0.79      0.74      0.70        23\n",
      "\n",
      "[[ 5  7  1]\n",
      " [ 3 32  1]\n",
      " [ 2  5  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.38      0.43        13\n",
      "         mid       0.73      0.89      0.80        36\n",
      "        good       0.50      0.22      0.31         9\n",
      "\n",
      "    accuracy                           0.67        58\n",
      "   macro avg       0.58      0.50      0.51        58\n",
      "weighted avg       0.64      0.67      0.64        58\n",
      "\n",
      "[[1 1 1]\n",
      " [6 6 6]\n",
      " [0 5 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.33      0.20         3\n",
      "         mid       0.50      0.33      0.40        18\n",
      "        good       0.42      0.50      0.45        10\n",
      "\n",
      "    accuracy                           0.39        31\n",
      "   macro avg       0.35      0.39      0.35        31\n",
      "weighted avg       0.44      0.39      0.40        31\n",
      "\n",
      "[[0 3 0]\n",
      " [3 6 0]\n",
      " [0 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.60      0.67      0.63         9\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.20      0.22      0.21        13\n",
      "weighted avg       0.42      0.46      0.44        13\n",
      "\n",
      "[[16 15  9]\n",
      " [12 49  6]\n",
      " [ 4 19  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.40      0.44        40\n",
      "         mid       0.59      0.73      0.65        67\n",
      "        good       0.29      0.21      0.24        29\n",
      "\n",
      "    accuracy                           0.52       136\n",
      "   macro avg       0.46      0.45      0.45       136\n",
      "weighted avg       0.50      0.52      0.50       136\n",
      "\n",
      "[[0 2 2]\n",
      " [0 9 3]\n",
      " [0 1 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         4\n",
      "         mid       0.75      0.75      0.75        12\n",
      "        good       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.58        19\n",
      "   macro avg       0.35      0.47      0.38        19\n",
      "weighted avg       0.52      0.58      0.54        19\n",
      "\n",
      "[[ 0  1  0]\n",
      " [ 2 11  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.92      0.85      0.88        13\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.31      0.28      0.29        14\n",
      "weighted avg       0.85      0.79      0.82        14\n",
      "\n",
      "[[ 2  0  0]\n",
      " [ 0 58  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         2\n",
      "         mid       1.00      1.00      1.00        58\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       0.67      0.67      0.67        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "[[1 0 0]\n",
      " [0 4 2]\n",
      " [0 1 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         1\n",
      "         mid       0.80      0.67      0.73         6\n",
      "        good       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.77      0.78      0.77        10\n",
      "weighted avg       0.73      0.70      0.71        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 18  2]\n",
      " [ 8 40 12]\n",
      " [ 3  8  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.35      0.23      0.28        26\n",
      "         mid       0.61      0.67      0.63        60\n",
      "        good       0.18      0.21      0.19        14\n",
      "\n",
      "    accuracy                           0.49       100\n",
      "   macro avg       0.38      0.37      0.37       100\n",
      "weighted avg       0.48      0.49      0.48       100\n",
      "\n",
      "[[ 4  3  0]\n",
      " [ 7 23  1]\n",
      " [ 2  5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.31      0.57      0.40         7\n",
      "         mid       0.74      0.74      0.74        31\n",
      "        good       0.50      0.12      0.20         8\n",
      "\n",
      "    accuracy                           0.61        46\n",
      "   macro avg       0.52      0.48      0.45        46\n",
      "weighted avg       0.63      0.61      0.60        46\n",
      "\n",
      "[[ 1  3  0]\n",
      " [ 1 10  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.25      0.33         4\n",
      "         mid       0.71      0.91      0.80        11\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.40      0.39      0.38        16\n",
      "weighted avg       0.62      0.69      0.63        16\n",
      "\n",
      "[[ 8 13  6]\n",
      " [ 7  9 14]\n",
      " [ 3  1  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.44      0.30      0.36        27\n",
      "         mid       0.39      0.30      0.34        30\n",
      "        good       0.13      0.43      0.20         7\n",
      "\n",
      "    accuracy                           0.31        64\n",
      "   macro avg       0.32      0.34      0.30        64\n",
      "weighted avg       0.39      0.31      0.33        64\n",
      "\n",
      "[[ 0  0  2]\n",
      " [ 0  3  2]\n",
      " [ 0  2 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.60      0.60      0.60         5\n",
      "        good       0.76      0.87      0.81        15\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.45      0.49      0.47        22\n",
      "weighted avg       0.66      0.73      0.69        22\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 1 21  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.95      0.98        22\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.33      0.32      0.33        22\n",
      "weighted avg       1.00      0.95      0.98        22\n",
      "\n",
      "[[4 2 1]\n",
      " [4 5 0]\n",
      " [0 2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.57      0.53         7\n",
      "         mid       0.56      0.56      0.56         9\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.35      0.38      0.36        18\n",
      "weighted avg       0.47      0.50      0.49        18\n",
      "\n",
      "[[10  4  8]\n",
      " [ 1 26 11]\n",
      " [ 1  4 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.83      0.45      0.59        22\n",
      "         mid       0.76      0.68      0.72        38\n",
      "        good       0.41      0.72      0.52        18\n",
      "\n",
      "    accuracy                           0.63        78\n",
      "   macro avg       0.67      0.62      0.61        78\n",
      "weighted avg       0.70      0.63      0.64        78\n",
      "\n",
      "[[ 0  1  2]\n",
      " [ 0 10  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.83      1.00      0.91        10\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.28      0.33      0.30        14\n",
      "weighted avg       0.60      0.71      0.65        14\n",
      "\n",
      "[[1 1 0]\n",
      " [1 3 0]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.50      0.50         2\n",
      "         mid       0.75      0.75      0.75         4\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.42      0.42      0.42         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 1 21  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      1.00      0.67         1\n",
      "         mid       1.00      0.95      0.98        22\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.50      0.65      0.55        23\n",
      "weighted avg       0.98      0.96      0.96        23\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 0 51  3]\n",
      " [ 1  9  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      1.00      0.67         1\n",
      "         mid       0.85      0.94      0.89        54\n",
      "        good       0.62      0.33      0.43        15\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.66      0.76      0.67        70\n",
      "weighted avg       0.80      0.81      0.79        70\n",
      "\n",
      "[[1 1 2]\n",
      " [3 4 3]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.25      0.25      0.25         4\n",
      "         mid       0.80      0.40      0.53        10\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.35      0.22      0.26        14\n",
      "weighted avg       0.64      0.36      0.45        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [ 8  2  3]\n",
      " [ 1  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.15      0.27        13\n",
      "        good       0.80      0.92      0.86        13\n",
      "\n",
      "    accuracy                           0.54        26\n",
      "   macro avg       0.60      0.36      0.37        26\n",
      "weighted avg       0.90      0.54      0.56        26\n",
      "\n",
      "[[47 13  8]\n",
      " [14 25  1]\n",
      " [ 1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.76      0.69      0.72        68\n",
      "         mid       0.66      0.62      0.64        40\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66       109\n",
      "   macro avg       0.47      0.44      0.45       109\n",
      "weighted avg       0.71      0.66      0.69       109\n",
      "\n",
      "[[ 1  1  0]\n",
      " [ 1 18  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.50      0.50         2\n",
      "         mid       0.90      0.95      0.92        19\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86        22\n",
      "   macro avg       0.47      0.48      0.47        22\n",
      "weighted avg       0.82      0.86      0.84        22\n",
      "\n",
      "[[ 1  2  0]\n",
      " [ 3 23  1]\n",
      " [ 3  1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.33      0.20         3\n",
      "         mid       0.88      0.85      0.87        27\n",
      "        good       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.73        37\n",
      "   macro avg       0.59      0.54      0.54        37\n",
      "weighted avg       0.80      0.73      0.75        37\n",
      "\n",
      "[[ 1  5  1]\n",
      " [ 1  7  4]\n",
      " [ 3  9 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.20      0.14      0.17         7\n",
      "         mid       0.33      0.58      0.42        12\n",
      "        good       0.85      0.71      0.77        41\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.46      0.48      0.45        60\n",
      "weighted avg       0.67      0.62      0.63        60\n",
      "\n",
      "[[0 2 1]\n",
      " [0 6 3]\n",
      " [0 1 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.67      0.67      0.67         9\n",
      "        good       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.37      0.47      0.40        16\n",
      "weighted avg       0.48      0.56      0.51        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 0]\n",
      " [0 4 0]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.57      1.00      0.73         4\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.19      0.33      0.24         7\n",
      "weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "[[ 1  8  2]\n",
      " [ 6 12 26]\n",
      " [ 8 21 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.07      0.09      0.08        11\n",
      "         mid       0.29      0.27      0.28        44\n",
      "        good       0.63      0.62      0.62        76\n",
      "\n",
      "    accuracy                           0.46       131\n",
      "   macro avg       0.33      0.33      0.33       131\n",
      "weighted avg       0.47      0.46      0.46       131\n",
      "\n",
      "[[0 0 0]\n",
      " [1 7 2]\n",
      " [1 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.70      0.82        10\n",
      "        good       0.75      0.86      0.80         7\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.58      0.52      0.54        17\n",
      "weighted avg       0.90      0.76      0.81        17\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 32  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        32\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       0.33      0.33      0.33        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "[[ 0  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.94      1.00      0.97        16\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        17\n",
      "   macro avg       0.31      0.33      0.32        17\n",
      "weighted avg       0.89      0.94      0.91        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  2]\n",
      " [ 6 45 27]\n",
      " [ 0 17 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.14      0.14         7\n",
      "         mid       0.68      0.58      0.62        78\n",
      "        good       0.37      0.50      0.42        34\n",
      "\n",
      "    accuracy                           0.53       119\n",
      "   macro avg       0.40      0.41      0.40       119\n",
      "weighted avg       0.56      0.53      0.54       119\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        10\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       0.33      0.33      0.33        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "[[ 2  4  6]\n",
      " [ 4 13 25]\n",
      " [ 4 17 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.20      0.17      0.18        12\n",
      "         mid       0.38      0.31      0.34        42\n",
      "        good       0.57      0.66      0.61        62\n",
      "\n",
      "    accuracy                           0.48       116\n",
      "   macro avg       0.38      0.38      0.38       116\n",
      "weighted avg       0.46      0.48      0.47       116\n",
      "\n",
      "[[ 7  5  5]\n",
      " [ 4 14  4]\n",
      " [ 0  2  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.64      0.41      0.50        17\n",
      "         mid       0.67      0.64      0.65        22\n",
      "        good       0.31      0.67      0.42         6\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.54      0.57      0.52        45\n",
      "weighted avg       0.61      0.56      0.56        45\n",
      "\n",
      "[[  0   0   0]\n",
      " [  0 111   0]\n",
      " [  0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00       111\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       111\n",
      "   macro avg       0.33      0.33      0.33       111\n",
      "weighted avg       1.00      1.00      1.00       111\n",
      "\n",
      "[[14  5 10]\n",
      " [ 7 12 14]\n",
      " [ 2  1  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.61      0.48      0.54        29\n",
      "         mid       0.67      0.36      0.47        33\n",
      "        good       0.08      0.40      0.13         5\n",
      "\n",
      "    accuracy                           0.42        67\n",
      "   macro avg       0.45      0.42      0.38        67\n",
      "weighted avg       0.60      0.42      0.47        67\n",
      "\n",
      "[[ 1  0  2]\n",
      " [ 0 20  2]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.33      0.50         3\n",
      "         mid       0.95      0.91      0.93        22\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.65      0.41      0.48        26\n",
      "weighted avg       0.92      0.81      0.84        26\n",
      "\n",
      "[[ 1  7  3]\n",
      " [ 1 10  8]\n",
      " [ 0  1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.50      0.09      0.15        11\n",
      "         mid       0.56      0.53      0.54        19\n",
      "        good       0.31      0.83      0.45         6\n",
      "\n",
      "    accuracy                           0.44        36\n",
      "   macro avg       0.46      0.48      0.38        36\n",
      "weighted avg       0.50      0.44      0.41        36\n",
      "\n",
      "[[ 0  2  0]\n",
      " [ 0  8  3]\n",
      " [ 0 14  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.33      0.73      0.46        11\n",
      "        good       0.75      0.39      0.51        23\n",
      "\n",
      "    accuracy                           0.47        36\n",
      "   macro avg       0.36      0.37      0.32        36\n",
      "weighted avg       0.58      0.47      0.47        36\n",
      "\n",
      "[[ 2  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      1.00      1.00         2\n",
      "         mid       0.95      1.00      0.97        18\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.65      0.67      0.66        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "[[ 3  1  1]\n",
      " [10 18  3]\n",
      " [ 5  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.17      0.60      0.26         5\n",
      "         mid       0.95      0.58      0.72        31\n",
      "        good       0.20      0.17      0.18         6\n",
      "\n",
      "    accuracy                           0.52        42\n",
      "   macro avg       0.44      0.45      0.39        42\n",
      "weighted avg       0.75      0.52      0.59        42\n",
      "\n",
      "[[ 5  9 12]\n",
      " [10 16 14]\n",
      " [ 4  3 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.26      0.19      0.22        26\n",
      "         mid       0.57      0.40      0.47        40\n",
      "        good       0.32      0.63      0.42        19\n",
      "\n",
      "    accuracy                           0.39        85\n",
      "   macro avg       0.38      0.41      0.37        85\n",
      "weighted avg       0.42      0.39      0.38        85\n",
      "\n",
      "[[ 5  4  0]\n",
      " [ 2 20  0]\n",
      " [ 1  8  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.56      0.59         9\n",
      "         mid       0.62      0.91      0.74        22\n",
      "        good       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.42      0.49      0.44        40\n",
      "weighted avg       0.48      0.62      0.54        40\n",
      "\n",
      "[[ 0  2  9]\n",
      " [ 2 10 22]\n",
      " [ 0  6 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00        11\n",
      "         mid       0.56      0.29      0.38        34\n",
      "        good       0.47      0.82      0.60        34\n",
      "\n",
      "    accuracy                           0.48        79\n",
      "   macro avg       0.34      0.37      0.33        79\n",
      "weighted avg       0.44      0.48      0.42        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 14  3]\n",
      " [19 18  1]\n",
      " [ 4  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.68      0.74      0.71        65\n",
      "         mid       0.55      0.47      0.51        38\n",
      "        good       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.61       108\n",
      "   macro avg       0.41      0.40      0.40       108\n",
      "weighted avg       0.60      0.61      0.60       108\n",
      "\n",
      "[[ 1  1  2]\n",
      " [ 0 10 16]\n",
      " [ 0  2  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.25      0.40         4\n",
      "         mid       0.77      0.38      0.51        26\n",
      "        good       0.22      0.71      0.33         7\n",
      "\n",
      "    accuracy                           0.43        37\n",
      "   macro avg       0.66      0.45      0.42        37\n",
      "weighted avg       0.69      0.43      0.47        37\n",
      "\n",
      "[[0 2 1]\n",
      " [1 3 4]\n",
      " [3 3 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         3\n",
      "         mid       0.38      0.38      0.38         8\n",
      "        good       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.25      0.24      0.24        20\n",
      "weighted avg       0.32      0.30      0.31        20\n",
      "\n",
      "[[0 0 0]\n",
      " [0 8 0]\n",
      " [0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00         8\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "[[1 0 1]\n",
      " [0 0 3]\n",
      " [0 1 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.50      0.67         2\n",
      "         mid       0.00      0.00      0.00         3\n",
      "        good       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.44      0.39      0.37         8\n",
      "weighted avg       0.38      0.38      0.33         8\n",
      "\n",
      "[[ 2  1  0]\n",
      " [ 1 16  1]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.67      0.67         3\n",
      "         mid       0.94      0.89      0.91        18\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.54      0.52      0.53        21\n",
      "weighted avg       0.90      0.86      0.88        21\n",
      "\n",
      "[[4 0 0]\n",
      " [2 8 2]\n",
      " [0 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      1.00      0.80         4\n",
      "         mid       1.00      0.67      0.80        12\n",
      "        good       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.67      0.89      0.70        17\n",
      "weighted avg       0.88      0.76      0.78        17\n",
      "\n",
      "[[0 0 0]\n",
      " [0 6 0]\n",
      " [0 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.86      1.00      0.92         6\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.29      0.33      0.31         7\n",
      "weighted avg       0.73      0.86      0.79         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6  0]\n",
      " [ 3 14  1]\n",
      " [ 1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.56      0.45      0.50        11\n",
      "         mid       0.70      0.78      0.74        18\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.42      0.41      0.41        30\n",
      "weighted avg       0.62      0.63      0.63        30\n",
      "\n",
      "[[ 1  2  0]\n",
      " [ 0 21  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.33      0.50         3\n",
      "         mid       0.88      1.00      0.93        21\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.62      0.44      0.48        25\n",
      "weighted avg       0.85      0.88      0.84        25\n",
      "\n",
      "[[ 8  8  1]\n",
      " [ 1  9 10]\n",
      " [ 4  8  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.47      0.53        17\n",
      "         mid       0.36      0.45      0.40        20\n",
      "        good       0.27      0.25      0.26        16\n",
      "\n",
      "    accuracy                           0.40        53\n",
      "   macro avg       0.41      0.39      0.40        53\n",
      "weighted avg       0.41      0.40      0.40        53\n",
      "\n",
      "[[0 0 0]\n",
      " [0 9 2]\n",
      " [0 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.90      0.82      0.86        11\n",
      "        good       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.30      0.27      0.29        12\n",
      "weighted avg       0.83      0.75      0.79        12\n",
      "\n",
      "[[ 5 12  1]\n",
      " [ 3  8  6]\n",
      " [ 1  1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.56      0.28      0.37        18\n",
      "         mid       0.38      0.47      0.42        17\n",
      "        good       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35        37\n",
      "   macro avg       0.31      0.25      0.26        37\n",
      "weighted avg       0.45      0.35      0.37        37\n",
      "\n",
      "[[ 0  5  1]\n",
      " [ 0 29  8]\n",
      " [ 0 10  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         6\n",
      "         mid       0.66      0.78      0.72        37\n",
      "        good       0.10      0.09      0.10        11\n",
      "\n",
      "    accuracy                           0.56        54\n",
      "   macro avg       0.25      0.29      0.27        54\n",
      "weighted avg       0.47      0.56      0.51        54\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 56  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        56\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       0.33      0.33      0.33        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "[[ 5  3  5]\n",
      " [12  6 12]\n",
      " [ 1  4  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.28      0.38      0.32        13\n",
      "         mid       0.46      0.20      0.28        30\n",
      "        good       0.29      0.58      0.39        12\n",
      "\n",
      "    accuracy                           0.33        55\n",
      "   macro avg       0.34      0.39      0.33        55\n",
      "weighted avg       0.38      0.33      0.31        55\n",
      "\n",
      "[[ 1  2  2]\n",
      " [ 3  2 13]\n",
      " [ 3  0 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.14      0.20      0.17         5\n",
      "         mid       0.50      0.11      0.18        18\n",
      "        good       0.52      0.84      0.64        19\n",
      "\n",
      "    accuracy                           0.45        42\n",
      "   macro avg       0.39      0.38      0.33        42\n",
      "weighted avg       0.46      0.45      0.39        42\n",
      "\n",
      "[[ 0  2  0]\n",
      " [ 0 17  0]\n",
      " [ 1  4  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         2\n",
      "         mid       0.74      1.00      0.85        17\n",
      "        good       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.25      0.33      0.28        24\n",
      "weighted avg       0.52      0.71      0.60        24\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 62  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        62\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        62\n",
      "   macro avg       0.33      0.33      0.33        62\n",
      "weighted avg       1.00      1.00      1.00        62\n",
      "\n",
      "[[ 2  6  4]\n",
      " [ 2 14  9]\n",
      " [ 2 10  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.33      0.17      0.22        12\n",
      "         mid       0.47      0.56      0.51        25\n",
      "        good       0.07      0.08      0.07        13\n",
      "\n",
      "    accuracy                           0.34        50\n",
      "   macro avg       0.29      0.27      0.27        50\n",
      "weighted avg       0.33      0.34      0.33        50\n",
      "\n",
      "[[0 1 0]\n",
      " [0 7 6]\n",
      " [0 2 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         1\n",
      "         mid       0.70      0.54      0.61        13\n",
      "        good       0.45      0.71      0.56         7\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.38      0.42      0.39        21\n",
      "weighted avg       0.58      0.57      0.56        21\n",
      "\n",
      "[[0 0 0]\n",
      " [0 5 3]\n",
      " [0 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      0.62      0.77         8\n",
      "        good       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.42      0.54      0.39         9\n",
      "weighted avg       0.92      0.67      0.73         9\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       0.88      0.88      0.88        17\n",
      "        good       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.41      0.41      0.41        20\n",
      "weighted avg       0.80      0.80      0.80        20\n",
      "\n",
      "[[7 3 2]\n",
      " [4 5 3]\n",
      " [2 3 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.54      0.58      0.56        12\n",
      "         mid       0.45      0.42      0.43        12\n",
      "        good       0.29      0.29      0.29         7\n",
      "\n",
      "    accuracy                           0.45        31\n",
      "   macro avg       0.43      0.43      0.43        31\n",
      "weighted avg       0.45      0.45      0.45        31\n",
      "\n",
      "[[ 0  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.00      0.00      0.00         0\n",
      "         mid       1.00      1.00      1.00        12\n",
      "        good       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       0.33      0.33      0.33        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\82102\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "labels = ['bad', 'mid', 'good']\n",
    "\n",
    "for pid, group in filtered_data.groupby('patient_id'):\n",
    "\n",
    "    # feature / target 나누기\n",
    "    y = group['score_level']\n",
    "    X = group.drop(columns=['sleep_quality_score', 'score_level', 'patient_id', 'timestamp'])\n",
    "    \n",
    "\n",
    "    # train/test split (시계열 고려해서 shuffle=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # 모델 정의\n",
    "    clf = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 예측\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 평가\n",
    "    print(confusion_matrix(y_test, y_pred, labels=labels))\n",
    "    print(classification_report(y_test, y_pred, labels=labels))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
